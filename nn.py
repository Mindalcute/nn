# -*- coding: utf-8 -*-
from __future__ import annotations

import os
import sys
import locale
import io
import base64
import re
from datetime import datetime, timedelta
import random
import numpy as np
import json
import smtplib
import ssl
import streamlit as st
from email.message import EmailMessage



# â€¦ the rest of your imports â€¦


# í™˜ê²½ ì„¤ì •
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['LANG'] = 'ko_KR.UTF-8'

try:
    locale.setlocale(locale.LC_ALL, 'ko_KR.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'Korean_Korea.utf8')
    except:
        pass

import streamlit as st
import pandas as pd
import requests
import zipfile
import xml.etree.ElementTree as ET
import feedparser

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ì„ íƒì‚¬í•­)
try:
    from dotenv import load_dotenv
    load_dotenv()
except:
    pass

# plotly ì•ˆì „í•˜ê²Œ import
try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

from bs4 import BeautifulSoup

# PDF ìƒì„±ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.lib import colors
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak, Image as RLImage, PageTemplate, Frame
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from reportlab.lib.units import inch
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# ì›Œë“œí´ë¼ìš°ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from wordcloud import WordCloud
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm
    WORDCLOUD_AVAILABLE = True
except ImportError:
    WORDCLOUD_AVAILABLE = False

# Gemini API
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# êµ¬ê¸€ì‹œíŠ¸ ì—°ë™ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
try:
    import gspread
    from google.oauth2.service_account import Credentials
    from google.oauth2 import service_account
    GOOGLE_SHEETS_AVAILABLE = True
except ImportError:
    GOOGLE_SHEETS_AVAILABLE = False

st.set_page_config(page_title="SKì—ë„ˆì§€ ê²½ìŸì‚¬ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", page_icon="âš¡", layout="wide")

# í•„ìˆ˜ í´ë˜ìŠ¤ ìµœì†Œ êµ¬í˜„ì²´ ì •ì˜
class FinancialDataProcessor:
    def load_file(self, file):
        # ì‹¤ì œ ë¡œì§ ì—†ìœ¼ë©´ ì„ì‹œ ë°˜í™˜
        return pd.DataFrame()

    def merge_company_data(self, dfs):
        return pd.concat(dfs, ignore_index=True)

    def create_comparison_report(self, merged_df):
        return "ë¹„êµ ë¶„ì„ AI ë¦¬í¬íŠ¸ ë‚´ìš©"

class SKNewsCollector:
    def collect_news(self):
        return pd.DataFrame()

class GeminiInsightGenerator:
    def generate_news_insight(self, keywords, titles):
        return "ë‰´ìŠ¤ AI ì¸ì‚¬ì´íŠ¸ ì˜ˆì‹œ"

# ë©”ì¸ ì•± UI ë° í•¨ìˆ˜ ì •ì˜
def main():
    tabs = st.tabs(["ìë™ ë°ì´í„°", "ìˆ˜ë™ ì—…ë¡œë“œ", "ë‰´ìŠ¤ ë¶„ì„", "ë³´ê³ ì„œ/ë©”ì¼"])
    
    # íƒ­2 ì˜ˆì‹œ (ìˆ˜ë™ XBRL ì—…ë¡œë“œ)
    with tabs[1]:
        processor = FinancialDataProcessor()
        # ... UI ì½”ë“œ ë° ë¡œì§
    
    # íƒ­3, íƒ­4 ë“±
    
if __name__ == "__main__":
    main()

# ==========================
# ì„¤ì • ë° ìƒìˆ˜
# ==========================


# API í‚¤ ì„¤ì •
DART_API_KEY = "9a153f4344ad2db546d651090f78c8770bd773cb"
GEMINI_API_KEY = "AIzaSyB176ys4MCjEs8R0dv15hMqDE2G-9J0qIA"

# êµ¬ê¸€ì‹œíŠ¸ ì„¤ì • (ìˆ˜ì •ë¨)
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/16g1G89xoxyqF32YLMD8wGYLnQzjq2F_ew6G1AHH4bCA/edit?usp=sharing"
SHEET_ID = "16g1G89xoxyqF32YLMD8wGYLnQzjq2F_ew6G1AHH4bCA"


# SK ë¸Œëœë“œ ì»¬ëŸ¬ í…Œë§ˆ
SK_COLORS = {
    'primary': '#E31E24',      # SK ë ˆë“œ
    'secondary': '#FF6B35',    # SK ì˜¤ë Œì§€
    'accent': '#004EA2',       # SK ë¸”ë£¨
    'success': '#00A651',      # ì„±ê³µ ìƒ‰ìƒ
    'warning': '#FF9500',      # ê²½ê³  ìƒ‰ìƒ
    'competitor': '#6C757D',   # ê¸°ë³¸ ê²½ìŸì‚¬ ìƒ‰ìƒ (íšŒìƒ‰)
    # ê°œë³„ ê²½ìŸì‚¬ íŒŒìŠ¤í…” ìƒ‰ìƒ
    'competitor_1': '#AEC6CF', # íŒŒìŠ¤í…” ë¸”ë£¨
    'competitor_2': '#FFB6C1', # íŒŒìŠ¤í…” í•‘í¬
    'competitor_3': '#98FB98', # íŒŒìŠ¤í…” ê·¸ë¦°
    'competitor_4': '#F0E68C', # íŒŒìŠ¤í…” ì˜ë¡œìš°
    'competitor_5': '#DDA0DD', # íŒŒìŠ¤í…” í¼í”Œ
}

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
session_vars = [
    'analysis_results', 'comparison_metric', 'quarterly_data', 'financial_data',
    'news_data', 'financial_insight', 'news_insight', 'selected_companies',
    'manual_financial_data', 'selected_charts'  # ìˆ˜ë™ ì—…ë¡œë“œìš© + ì°¨íŠ¸ ì„ íƒ ì¶”ê°€
]

for var in session_vars:
    if var not in st.session_state:
        st.session_state[var] = None

if 'comparison_metric' not in st.session_state:
    st.session_state.comparison_metric = "ë§¤ì¶œ ëŒ€ë¹„ ë¹„ìœ¨"

# ==========================
# íšŒì‚¬ë³„ ìƒ‰ìƒ í• ë‹¹ í•¨ìˆ˜
# ==========================

def get_company_color(company_name, all_companies):
    """íšŒì‚¬ë³„ ê³ ìœ  ìƒ‰ìƒ ë°˜í™˜ (SKëŠ” ë¹¨ê°„ìƒ‰, ê²½ìŸì‚¬ëŠ” íŒŒìŠ¤í…” êµ¬ë¶„)"""
    if 'SK' in company_name:
        return SK_COLORS['primary']
    else:
        # ê²½ìŸì‚¬ë“¤ì—ê²Œ ì„œë¡œ ë‹¤ë¥¸ íŒŒìŠ¤í…” ìƒ‰ìƒ í• ë‹¹
        competitor_colors = [
            SK_COLORS['competitor_1'], # íŒŒìŠ¤í…” ë¸”ë£¨
            SK_COLORS['competitor_2'], # íŒŒìŠ¤í…” í•‘í¬
            SK_COLORS['competitor_3'], # íŒŒìŠ¤í…” ê·¸ë¦°
            SK_COLORS['competitor_4'], # íŒŒìŠ¤í…” ì˜ë¡œìš°
            SK_COLORS['competitor_5']  # íŒŒìŠ¤í…” í¼í”Œ
        ]
        
        # SKê°€ ì•„ë‹Œ íšŒì‚¬ë“¤ì˜ ì¸ë±ìŠ¤ ê³„ì‚°
        non_sk_companies = [comp for comp in all_companies if 'SK' not in comp]
        try:
            index = non_sk_companies.index(company_name)
            return competitor_colors[index % len(competitor_colors)]
        except ValueError:
            return SK_COLORS['competitor']

# ==========================
# í”„ë¡œê·¸ë ˆìŠ¤ë°” ê°œì„  í•¨ìˆ˜
# ==========================

def collect_financial_data_with_progress(dart_collector, sk_processor, selected_companies, analysis_year):
    """í”„ë¡œê·¸ë ˆìŠ¤ë°”ê°€ ìˆëŠ” ë°ì´í„° ìˆ˜ì§‘"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    dataframes = []
    total_companies = len(selected_companies)
    
    for idx, company in enumerate(selected_companies):
        progress = (idx + 1) / total_companies
        status_text.text(f"ğŸ“Š {company} ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({idx + 1}/{total_companies})")
        progress_bar.progress(progress)
        
        dart_df = dart_collector.get_company_financials_auto(company, analysis_year)
        if dart_df is not None and not dart_df.empty:
            processed_df = sk_processor.process_dart_data(dart_df, company)
            if processed_df is not None:
                dataframes.append(processed_df)
    
    status_text.text("âœ… ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    progress_bar.progress(1.0)
    
    return dataframes

# ==========================
# ë¶„ê¸°ë³„ ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤ (í”„ë¡œê·¸ë ˆìŠ¤ë°” ê°œì„ )
# ==========================

class QuarterlyDataCollector:
    def __init__(self, dart_collector):
        self.dart_collector = dart_collector
        self.report_codes = {
            "Q1": "11013", # 1ë¶„ê¸°
            "Q2": "11012", # ë°˜ê¸° (1,2ë¶„ê¸° ëˆ„ì )
            "Q3": "11014", # 3ë¶„ê¸°
            "Q4": "11011"  # ì‚¬ì—…ë³´ê³ ì„œ (ì—°ê°„)
        }

    def collect_quarterly_data(self, company_name, year=2024):
        """ë¶„ê¸°ë³„ ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘ (í”„ë¡œê·¸ë ˆìŠ¤ë°” í¬í•¨)"""
        quarterly_results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_quarters = len(self.report_codes)
        
        for idx, (quarter, report_code) in enumerate(self.report_codes.items()):
            progress = (idx + 1) / total_quarters
            status_text.text(f"ğŸ“Š {company_name} {quarter} ë°ì´í„° ìˆ˜ì§‘ì¤‘... ({idx + 1}/{total_quarters})")
            progress_bar.progress(progress)
            
            corp_code = self.dart_collector.get_corp_code_enhanced(company_name)
            if not corp_code:
                continue
                
            df = self.dart_collector.get_financial_statement(corp_code, str(year), report_code)
            if not df.empty:
                # ì£¼ìš” ì§€í‘œ ì¶”ì¶œ
                quarterly_metrics = self._extract_key_metrics(df, quarter)
                if quarterly_metrics:
                    quarterly_metrics['íšŒì‚¬'] = company_name
                    quarterly_metrics['ì—°ë„'] = year
                    quarterly_results.append(quarterly_metrics)
        
        status_text.text(f"âœ… {company_name} ë¶„ê¸°ë³„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        progress_bar.progress(1.0)
        
        return pd.DataFrame(quarterly_results) if quarterly_results else pd.DataFrame()

    def _extract_key_metrics(self, df, quarter):
        """ì£¼ìš” ì¬ë¬´ ì§€í‘œ ì¶”ì¶œ"""
        metrics = {'ë¶„ê¸°': quarter}
        
        # ë§¤ì¶œì•¡ ì¶”ì¶œ
        revenue_keywords = ['ë§¤ì¶œì•¡', 'revenue', 'sales']
        for keyword in revenue_keywords:
            revenue_rows = df[df['account_nm'].str.contains(keyword, case=False, na=False)]
            if not revenue_rows.empty:
                try:
                    amount = float(str(revenue_rows.iloc[0]['thstrm_amount']).replace(',', '').replace('-', '0'))
                    metrics['ë§¤ì¶œì•¡'] = amount / 1_000_000_000_000  # ì¡°ì› ë‹¨ìœ„
                    break
                except:
                    continue
        
        # ì˜ì—…ì´ìµ ì¶”ì¶œ
        operating_keywords = ['ì˜ì—…ì´ìµ', 'operating']
        for keyword in operating_keywords:
            op_rows = df[df['account_nm'].str.contains(keyword, case=False, na=False)]
            if not op_rows.empty:
                try:
                    amount = float(str(op_rows.iloc[0]['thstrm_amount']).replace(',', '').replace('-', '0'))
                    metrics['ì˜ì—…ì´ìµ'] = amount / 100_000_000  # ì–µì› ë‹¨ìœ„
                    break
                except:
                    continue
        
        # ì˜ì—…ì´ìµë¥  ê³„ì‚°
        if 'ë§¤ì¶œì•¡' in metrics and 'ì˜ì—…ì´ìµ' in metrics and metrics['ë§¤ì¶œì•¡'] > 0:
            metrics['ì˜ì—…ì´ìµë¥ '] = (metrics['ì˜ì—…ì´ìµ'] * 100) / (metrics['ë§¤ì¶œì•¡'] * 10)  # % ë‹¨ìœ„
        
        return metrics if len(metrics) > 1 else None

# ==========================
# DART API ì—°ë™ í´ë˜ìŠ¤ (rcept_no ì¶”ê°€)
# ==========================

class DartAPICollector:
    def __init__(self, api_key):
        self.api_key = api_key
        # ì¶œì²˜ ì¶”ì ìš© ë”•ì…”ë„ˆë¦¬
        self.source_tracking = {}
        
        # íšŒì‚¬ëª… ë§¤í•‘ ê°œì„ 
# DartAPICollector í´ë˜ìŠ¤ì˜ __init__ ë©”ì„œë“œì—ì„œ íšŒì‚¬ëª… ë§¤í•‘ ë¶€ë¶„ ìˆ˜ì •
        self.company_name_mapping = {
            "SKì—ë„ˆì§€": [
                "SKì—ë„ˆì§€", "SKì—ë„ˆì§€ì£¼ì‹íšŒì‚¬", "ì—ìŠ¤ì¼€ì´ì—ë„ˆì§€",
                "SK ENERGY", "SK Energy Co., Ltd."
            ],
            "GSì¹¼í…ìŠ¤": [
                "GSì¹¼í…ìŠ¤", "ì§€ì—ìŠ¤ì¹¼í…ìŠ¤", "GSì¹¼í…ìŠ¤ì£¼ì‹íšŒì‚¬", "ì§€ì—ìŠ¤ì¹¼í…ìŠ¤ì£¼ì‹íšŒì‚¬"
            ],
            # HDí˜„ëŒ€ì˜¤ì¼ë±…í¬ ë§¤í•‘ ê°•í™”
            "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬": [
                "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬ì£¼ì‹íšŒì‚¬", 
                "í˜„ëŒ€ì˜¤ì¼ë±…í¬", "í˜„ëŒ€ì˜¤ì¼ë±…í¬ì£¼ì‹íšŒì‚¬",
                "HYUNDAI OILBANK", "Hyundai Oilbank Co., Ltd.",
                "267250"  # ì¢…ëª©ì½”ë“œ ì¶”ê°€
            ],
            "í˜„ëŒ€ì˜¤ì¼ë±…í¬": [
                "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬ì£¼ì‹íšŒì‚¬",
                "í˜„ëŒ€ì˜¤ì¼ë±…í¬", "í˜„ëŒ€ì˜¤ì¼ë±…í¬ì£¼ì‹íšŒì‚¬"
            ],
            "S-Oil": [
                "S-Oil", "S-Oil Corporation", "S-Oil Corp", "ì—ì“°ì˜¤ì¼", "ì—ìŠ¤ì˜¤ì¼",
                "ì£¼ì‹íšŒì‚¬S-Oil", "S-OIL", "s-oil", "010950"
            ]
        }

        # STOCK_CODE_MAPPINGë„ ì—…ë°ì´íŠ¸
        STOCK_CODE_MAPPING = {
            "S-Oil": "010950",
            "GSì¹¼í…ìŠ¤": "089590", 
            "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬": "267250",
            "í˜„ëŒ€ì˜¤ì¼ë±…í¬": "267250",
            "SKì—ë„ˆì§€": "096770",
        }


    def get_corp_code_enhanced(self, company_name):
        """ê°•í™”ëœ íšŒì‚¬ ê³ ìœ ë²ˆí˜¸ ì¡°íšŒ (ì¶œë ¥ ê°„ì†Œí™”)"""
        url = f"https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={self.api_key}"
        search_names = self.company_name_mapping.get(company_name, [company_name])
        
        try:
            res = requests.get(url)
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                xml_file = z.open(z.namelist()[0])
                tree = ET.parse(xml_file)
                root = tree.getroot()
            
            # ëª¨ë“  íšŒì‚¬ ëª©ë¡ì—ì„œ ë§¤ì¹­ ì‹œë„
            all_companies = []
            for corp in root.findall("list"):
                corp_name_elem = corp.find("corp_name")
                corp_code_elem = corp.find("corp_code")
                stock_code_elem = corp.find("stock_code")
                
                if corp_name_elem is not None and corp_code_elem is not None:
                    all_companies.append({
                        'name': corp_name_elem.text,
                        'code': corp_code_elem.text,
                        'stock_code': stock_code_elem.text if stock_code_elem is not None else None
                    })
            
            # ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ê²€ìƒ‰
            for search_name in search_names:
                # 1ë‹¨ê³„: ì¢…ëª©ì½”ë“œë¡œ ê²€ìƒ‰ (S-Oil ì „ìš©)
                if search_name.isdigit():
                    for company in all_companies:
                        if company['stock_code'] == search_name:
                            return company['code']
                
                # 2ë‹¨ê³„: ì •í™•íˆ ì¼ì¹˜
                for company in all_companies:
                    if company['name'] == search_name:
                        return company['code']
                
                # 3ë‹¨ê³„: í¬í•¨ ê²€ìƒ‰
                for company in all_companies:
                    if search_name in company['name'] or company['name'] in search_name:
                        return company['code']
                
                # 4ë‹¨ê³„: ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ê²€ìƒ‰
                for company in all_companies:
                    if search_name.lower() in company['name'].lower() or company['name'].lower() in search_name.lower():
                        return company['code']
            
            return None
            
        except Exception as e:
            st.error(f"íšŒì‚¬ ì½”ë“œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None

    def get_financial_statement(self, corp_code, bsns_year, reprt_code, fs_div="CFS"):
        """ì¬ë¬´ì œí‘œ ì¡°íšŒ"""
        url = "https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json"
        params = {
            "crtfc_key": self.api_key,
            "corp_code": corp_code,
            "bsns_year": bsns_year,
            "reprt_code": reprt_code,
            "fs_div": fs_div
        }
        
        try:
            res = requests.get(url, params=params).json()
            if res.get("status") == "000" and "list" in res:
                df = pd.DataFrame(res["list"])
                df["ë³´ê³ ì„œêµ¬ë¶„"] = reprt_code
                return df
            else:
                return pd.DataFrame()
        except Exception as e:
            return pd.DataFrame()

    def get_company_financials_auto(self, company_name, bsns_year):
        """íšŒì‚¬ ì¬ë¬´ì œí‘œ ìë™ ìˆ˜ì§‘ (ì¶œì²˜ ì¶”ì  í¬í•¨)"""
        # ì¢…ëª©ì½”ë“œ ì§ì ‘ ë§¤í•‘
        STOCK_CODE_MAPPING = {
            "S-Oil": "010950",
            "GSì¹¼í…ìŠ¤": "089590", 
            "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬": "267250",  # HDí˜„ëŒ€ì˜¤ì¼ë±…í¬ ì¶”ê°€
            "í˜„ëŒ€ì˜¤ì¼ë±…í¬": "267250",    # í˜„ëŒ€ì˜¤ì¼ë±…í¬ë„ ê°™ì€ ì½”ë“œ
            "SKì—ë„ˆì§€": "096770",
        }
        
        # 1. ì¢…ëª©ì½”ë“œë¡œ ì§ì ‘ ì‹œë„
        if company_name in STOCK_CODE_MAPPING:
            stock_code = STOCK_CODE_MAPPING[company_name]
            corp_code = self.convert_stock_to_corp_code(stock_code)
            if corp_code:
                # ì¬ë¬´ì œí‘œ ì§ì ‘ ì¡°íšŒ
                report_codes = ["11011", "11014", "11012"]
                for report_code in report_codes:
                    df = self.get_financial_statement(corp_code, bsns_year, report_code)
                    if not df.empty:
                        # rcept_no ìƒì„± ë° ì¶œì²˜ ì •ë³´ ì €ì¥ (ê°œì„ )
                        rcept_no = self._generate_rcept_no(corp_code, bsns_year, report_code)
                        self._save_source_info(company_name, corp_code, report_code, bsns_year, rcept_no)
                        return df
        
        # 2. ê¸°ì¡´ ê²€ìƒ‰ ë°©ì‹ìœ¼ë¡œ í´ë°±
        corp_code = self.get_corp_code_enhanced(company_name)
        if not corp_code:
            return None
        
        # ì—¬ëŸ¬ ë³´ê³ ì„œ íƒ€ì… ì‹œë„
        report_codes = ["11011", "11014", "11012"]
        for report_code in report_codes:
            df = self.get_financial_statement(corp_code, bsns_year, report_code)
            if not df.empty:
                # rcept_no ìƒì„± ë° ì¶œì²˜ ì •ë³´ ì €ì¥ (ê°œì„ )
                rcept_no = self._generate_rcept_no(corp_code, bsns_year, report_code)
                self._save_source_info(company_name, corp_code, report_code, bsns_year, rcept_no)
                return df
        
        return None

    def convert_stock_to_corp_code(self, stock_code):
        """ì¢…ëª©ì½”ë“œë¥¼ DART íšŒì‚¬ì½”ë“œë¡œ ë³€í™˜"""
        try:
            url = f"https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={self.api_key}"
            res = requests.get(url)
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                xml_file = z.open(z.namelist()[0])
                tree = ET.parse(xml_file)
                root = tree.getroot()
            
            # ì¢…ëª©ì½”ë“œë¡œ ë§¤ì¹­
            for corp in root.findall("list"):
                stock_elem = corp.find("stock_code")
                corp_code_elem = corp.find("corp_code")
                
                if (stock_elem is not None and 
                    corp_code_elem is not None and 
                    stock_elem.text == stock_code):
                    return corp_code_elem.text
            
            return None
        except Exception as e:
            return None

    def _generate_rcept_no(self, corp_code, bsns_year, report_code):
        """rcept_no ìƒì„± (ì‹¤ì œ APIì—ì„œ ê°€ì ¸ì˜¤ê¸°)"""
        try:
            # DART APIì˜ ê³µì‹œëª©ë¡ ì¡°íšŒ
            url = "https://opendart.fss.or.kr/api/list.json"
            params = {
                "crtfc_key": self.api_key,
                "corp_code": corp_code,
                "bgn_de": f"{bsns_year}0101",
                "end_de": f"{bsns_year}1231",
                "pblntf_ty": "A",  # ì •ê¸°ê³µì‹œ
                "corp_cls": "Y",   # ìœ ê°€ì¦ê¶Œ
                "page_no": 1,
                "page_count": 100
            }
            
            res = requests.get(url, params=params).json()
            if res.get("status") == "000" and "list" in res:
                # í•´ë‹¹ ë³´ê³ ì„œ íƒ€ì…ì— ë§ëŠ” rcept_no ì°¾ê¸°
                report_keywords = {
                    "11011": ["ì‚¬ì—…ë³´ê³ ì„œ"],
                    "11014": ["ë¶„ê¸°ë³´ê³ ì„œ", "3ë¶„ê¸°"],
                    "11012": ["ë°˜ê¸°ë³´ê³ ì„œ"],
                    "11013": ["ë¶„ê¸°ë³´ê³ ì„œ", "1ë¶„ê¸°"]
                }
                
                keywords = report_keywords.get(report_code, [])
                for item in res["list"]:
                    report_nm = item.get("report_nm", "")
                    if any(keyword in report_nm for keyword in keywords):
                        return item.get("rcept_no")
            
            return f"{corp_code}_{bsns_year}_{report_code}"  # ê¸°ë³¸ê°’
        except:
            return f"{corp_code}_{bsns_year}_{report_code}"

    def _save_source_info(self, company_name, corp_code, report_code, bsns_year, rcept_no):
        """ì¶œì²˜ ì •ë³´ ì €ì¥ (ê°œì„ ëœ ë²„ì „)"""
        report_type_map = {
            "11011": "ì‚¬ì—…ë³´ê³ ì„œ",
            "11014": "3ë¶„ê¸°ë³´ê³ ì„œ",
            "11012": "ë°˜ê¸°ë³´ê³ ì„œ",
            "11013": "1ë¶„ê¸°ë³´ê³ ì„œ"
        }
        
        self.source_tracking[company_name] = {
            'company_code': corp_code,
            'report_code': report_code,
            'report_type': report_type_map.get(report_code, "ì¬ë¬´ì œí‘œ"),
            'year': bsns_year,
            'rcept_no': rcept_no,
            'dart_url': f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}",
            'direct_link': f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}&reprtCode={report_code}"
        }

# ==========================
# SK ì¤‘ì‹¬ ì¬ë¬´ë°ì´í„° í”„ë¡œì„¸ì„œ
# ==========================
# ==========================
# ìˆ˜ë™ XBRL ì—…ë¡œë“œìš© ì¬ë¬´ë°ì´í„° í”„ë¡œì„¸ì„œ (ì™„ì „ ê°œì„  ë²„ì „)
# ==========================

class FinancialDataProcessor:
    # ë” í¬ê´„ì í•œ XBRL íƒœê·¸ ë§¤í•‘ (ì •ê·œì‹ íŒ¨í„´)
    INCOME_STATEMENT_PATTERNS = {
        # ë§¤ì¶œ ê´€ë ¨ (ë” ê´‘ë²”ìœ„í•œ íŒ¨í„´)
        r'(revenue|sales|ë§¤ì¶œ|ìˆ˜ìµ|ì´ë§¤ì¶œ|ë§¤ì¶œìˆ˜ìµ|operating.*revenue)(?!.*cost|ì›ê°€|ë¹„ìš©)': 'ë§¤ì¶œì•¡',
        r'(cost.*revenue|cost.*sales|cost.*goods|ë§¤ì¶œì›ê°€|ì›ê°€|íŒë§¤ì›ê°€|ì œí’ˆë§¤ì¶œì›ê°€)': 'ë§¤ì¶œì›ê°€',
        
        # ì´ìµ ê´€ë ¨
        r'(gross.*profit|ì´ì´ìµ|ë§¤ì¶œì´ì´ìµ|ì´ìˆ˜ìµ)': 'ë§¤ì¶œì´ì´ìµ',
        r'(operating.*income|operating.*profit|ì˜ì—…ì´ìµ|ì˜ì—…ì†ìµ|ì˜ì—…ìˆ˜ìµ)(?!.*ë¹„ìš©|expense)': 'ì˜ì—…ì´ìµ',
        r'(net.*income|net.*profit|ë‹¹ê¸°ìˆœì´ìµ|ìˆœì´ìµ|ë‹¹ê¸°.*ìˆœì†ìµ|net.*earnings)(?!.*loss)': 'ë‹¹ê¸°ìˆœì´ìµ',
        
        # ë¹„ìš© ê´€ë ¨ (ë” ì •í™•í•œ íŒ¨í„´)
        r'(selling.*expense|selling.*cost|íŒë§¤ë¹„|íŒë§¤ë¹„ìš©|íŒë§¤ê´€ë ¨ë¹„ìš©)': 'íŒë§¤ë¹„',
        r'(administrative.*expense|administrative.*cost|ê´€ë¦¬ë¹„|ê´€ë¦¬ë¹„ìš©|ì¼ë°˜ê´€ë¦¬ë¹„)': 'ê´€ë¦¬ë¹„',
        r'(selling.*administrative|íŒë§¤ë¹„.*ê´€ë¦¬ë¹„|íŒê´€ë¹„|íŒë§¤.*ê´€ë¦¬.*ë¹„ìš©)': 'íŒê´€ë¹„',
        r'(employee.*benefit|employee.*cost|wage|salary|ì¸ê±´ë¹„|ê¸‰ì—¬|ì„ê¸ˆ)': 'ì¸ê±´ë¹„',
        r'(depreciation|amortization|ê°ê°€ìƒê°|ìƒê°ë¹„|ê°ê°€ìƒê°ë¹„)': 'ê°ê°€ìƒê°ë¹„',
        
        # ê¸°íƒ€ í•­ëª©
        r'(interest.*expense|interest.*cost|ì´ìë¹„ìš©|ì´ìì§€ê¸‰)': 'ì´ìë¹„ìš©',
        r'(financial.*cost|ê¸ˆìœµë¹„ìš©|ê¸ˆìœµì›ê°€)': 'ê¸ˆìœµë¹„ìš©',
        r'(non.*operating.*income|ì˜ì—…ì™¸ìˆ˜ìµ|ê¸°íƒ€ìˆ˜ìµ)': 'ì˜ì—…ì™¸ìˆ˜ìµ',
        r'(non.*operating.*expense|ì˜ì—…ì™¸ë¹„ìš©|ê¸°íƒ€ë¹„ìš©)': 'ì˜ì—…ì™¸ë¹„ìš©'
    }
    
    def __init__(self):
        self.company_data = {}
        # ì •ê·œì‹ ë¯¸ë¦¬ ì»´íŒŒì¼ (ì„±ëŠ¥ í–¥ìƒ)
        self.compiled_patterns = {}
        for pattern, item in self.INCOME_STATEMENT_PATTERNS.items():
            self.compiled_patterns[re.compile(pattern, re.IGNORECASE)] = item

    def load_file(self, uploaded_file):
        """ê°œì„ ëœ XBRL íŒŒì¼ ë¡œë“œ (ì†ë„ ìµœì í™” + ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)"""
        try:
            # íŒŒì¼ í¬ê¸° ì²´í¬ (50MB ì œí•œ)
            file_size = uploaded_file.size if hasattr(uploaded_file, 'size') else 0
            if file_size > 50 * 1024 * 1024:
                st.error(f"âŒ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ ({file_size/(1024*1024):.1f}MB). 50MB ì´í•˜ë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                return None
            
            # íŒŒì¼ ì²˜ìŒë¶€í„° ì½ê¸°
            uploaded_file.seek(0)
            content = uploaded_file.read()
            
            # ë¹ ë¥¸ ì¸ì½”ë”© ê°ì§€ ë° ë””ì½”ë”©
            content_str = self._fast_decode(content)
            if not content_str:
                st.error("âŒ íŒŒì¼ ì¸ì½”ë”©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # XML íŒŒì‹± (ë” ì•ˆì „í•œ ë°©ì‹)
            try:
                # lxmlì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ xml íŒŒì„œ ì‚¬ìš©
                soup = BeautifulSoup(content_str, 'lxml-xml')
                if not soup.find():  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ íŒŒì„œ ì‚¬ìš©
                    soup = BeautifulSoup(content_str, 'xml')
            except Exception:
                soup = BeautifulSoup(content_str, 'html.parser')  # ìµœí›„ ìˆ˜ë‹¨
            
            # íšŒì‚¬ëª… ì¶”ì¶œ (ë” ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ)
            company_name = self._extract_company_name_fast(soup, uploaded_file.name)
            
            # ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ (ìµœì í™”ëœ ë²„ì „)
            financial_data = self._extract_financial_items_optimized(soup)
            
            if not financial_data:
                st.warning(f"âš ï¸ {uploaded_file.name}ì—ì„œ ì¬ë¬´ í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ íŒŒì¼ì´ í‘œì¤€ XBRL í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return None
            
            # í‘œì¤€ ì†ìµê³„ì‚°ì„œ êµ¬ì¡°ë¡œ ë³€í™˜
            income_statement = self._create_income_statement(financial_data, company_name)
            return income_statement
            
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            st.info("ğŸ’¡ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return None

    def _fast_decode(self, content):
        """ìµœì í™”ëœ ì¸ì½”ë”© ê°ì§€ ë° ë””ì½”ë”©"""
        # ê°€ì¥ ì¼ë°˜ì ì¸ ì¸ì½”ë”©ë¶€í„° ì‹œë„ (í•œêµ­ì–´ í™˜ê²½ ìµœì í™”)
        encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'iso-8859-1', 'ascii']
        
        for encoding in encodings:
            try:
                decoded = content.decode(encoding)
                # í•œê¸€ì´ ì œëŒ€ë¡œ ë””ì½”ë”©ë˜ì—ˆëŠ”ì§€ ê°„ë‹¨íˆ ì²´í¬
                if 'ë§¤ì¶œ' in decoded or 'revenue' in decoded.lower():
                    return decoded
                return decoded  # í•œê¸€ì´ ì—†ì–´ë„ ì„±ê³µí•œ ë””ì½”ë”©ì€ ë°˜í™˜
            except (UnicodeDecodeError, UnicodeError):
                continue
        
        # ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë¬´ì‹œí•˜ê³  ë””ì½”ë”©
        try:
            return content.decode('utf-8', errors='ignore')
        except:
            return None

    def _extract_company_name_fast(self, soup, filename):
        """ìµœì í™”ëœ íšŒì‚¬ëª… ì¶”ì¶œ"""
        # 1ë‹¨ê³„: í‘œì¤€ XBRL íƒœê·¸ì—ì„œ íšŒì‚¬ëª… ê²€ìƒ‰
        company_tags = [
            'EntityRegistrantName', 'CompanyName', 'entity', 'registrant',
            'ReportingEntityName', 'EntityName', 'CorporateName'
        ]
        
        for tag_name in company_tags:
            # ì •í™•í•œ íƒœê·¸ëª…ìœ¼ë¡œ ë¨¼ì € ê²€ìƒ‰
            node = soup.find(tag_name)
            if node and node.string and len(node.string.strip()) > 1:
                return node.string.strip()
            
            # ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ê²€ìƒ‰ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            node = soup.find(lambda t: t.name and tag_name.lower() in t.name.lower())
            if node and node.string and len(node.string.strip()) > 1:
                return node.string.strip()
        
        # 2ë‹¨ê³„: íŒŒì¼ëª…ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ (ê°•í™”ëœ ë§¤í•‘)
        name = filename.split('.')[0].lower()
        name_mapping = {
            'sk': 'SKì—ë„ˆì§€',
            'skenergy': 'SKì—ë„ˆì§€',
            'gs': 'GSì¹¼í…ìŠ¤',
            'gscaltex': 'GSì¹¼í…ìŠ¤',
            'hd': 'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬',
            'hyundai': 'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬',
            'hdoil': 'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬',
            's-oil': 'S-Oil',
            'soil': 'S-Oil',
            'soilcorp': 'S-Oil'
        }
        
        for key, company in name_mapping.items():
            if key in name:
                return company
        
        # 3ë‹¨ê³„: íŒŒì¼ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì •ë¦¬í•´ì„œ)
        clean_name = re.sub(r'[^A-Za-zê°€-í£0-9\s]', '', filename.split('.')[0])
        return clean_name if clean_name else "Unknown Company"

    def _extract_financial_items_optimized(self, soup):
        """ìµœì í™”ëœ ì¬ë¬´ í•­ëª© ì¶”ì¶œ"""
        items = {}
        processed_count = 0
        
        # ìˆ«ìê°€ í¬í•¨ëœ íƒœê·¸ë§Œ ì‚¬ì „ í•„í„°ë§ (ì„±ëŠ¥ í–¥ìƒ)
        numeric_tags = []
        for tag in soup.find_all():
            if tag.string and re.search(r'\d', tag.string):
                numeric_tags.append(tag)
        
        if not numeric_tags:
            st.warning("ğŸ“Š ìˆ«ì ë°ì´í„°ê°€ í¬í•¨ëœ íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return items
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        st.info(f"ğŸ” {len(numeric_tags)}ê°œì˜ ìˆ«ì íƒœê·¸ ë°œê²¬, ë¶„ì„ ì¤‘...")
        
        # ê° íƒœê·¸ ë¶„ì„
        for tag in numeric_tags:
            tag_text = tag.string.strip()
            
            # ìˆ«ì ì¶”ì¶œ ë° ê²€ì¦
            try:
                # ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ìŒìˆ˜ ì²˜ë¦¬
                if '(' in tag_text and ')' in tag_text:
                    number_str = re.sub(r'[^\d.]', '', tag_text.replace('(', '').replace(')', ''))
                    if number_str:
                        value = -float(number_str)
                    else:
                        continue
                else:
                    # ì¼ë°˜ì ì¸ ìˆ«ì ì¶”ì¶œ
                    number_str = re.sub(r'[^\d.-]', '', tag_text)
                    if number_str and number_str not in ['-', '.', '-.']:
                        value = float(number_str)
                    else:
                        continue
                
                # ë„ˆë¬´ ì‘ì€ ê°’ì€ ì œì™¸ (ë…¸ì´ì¦ˆ ì œê±°)
                if abs(value) < 1000:
                    continue
                    
            except (ValueError, TypeError):
                continue
            
            # íƒœê·¸ ì •ë³´ êµ¬ì„± (íƒœê·¸ëª… + ì†ì„±)
            tag_info_parts = [tag.name.lower() if tag.name else '']
            if tag.attrs:
                tag_info_parts.extend([str(v).lower() for v in tag.attrs.values()])
            tag_info = ' '.join(tag_info_parts)
            
            # ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­
            for pattern, standard_item in self.compiled_patterns.items():
                if pattern.search(tag_info):
                    # ê°™ì€ í•­ëª©ì´ ì´ë¯¸ ìˆìœ¼ë©´ ë” í° ì ˆëŒ“ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                    if standard_item not in items or abs(value) > abs(items[standard_item]):
                        items[standard_item] = value
                    processed_count += 1
                    break
        
        # ê²°ê³¼ ìš”ì•½ í‘œì‹œ
        if items:
            st.success(f"âœ… {len(items)}ê°œ ì¬ë¬´í•­ëª© ì¶”ì¶œ (ì´ {processed_count}ê°œ íƒœê·¸ ì²˜ë¦¬)")
            with st.expander("ğŸ” ì¶”ì¶œëœ ë°ì´í„° ìƒì„¸ ë³´ê¸°"):
                for key, value in items.items():
                    formatted_value = self._format_amount(value)
                    st.write(f"**{key}**: {formatted_value}")
        else:
            st.warning("âš ï¸ í‘œì¤€ ì¬ë¬´ í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return items

    def _create_income_statement(self, data, company_name):
        """í‘œì¤€ ì†ìµê³„ì‚°ì„œ êµ¬ì¡° ìƒì„±"""
        # í‘œì¤€ ì†ìµê³„ì‚°ì„œ í•­ëª© ìˆœì„œ
        standard_items = [
            'ë§¤ì¶œì•¡', 'ë§¤ì¶œì›ê°€', 'ë§¤ì¶œì´ì´ìµ', 'íŒë§¤ë¹„', 'ê´€ë¦¬ë¹„', 'íŒê´€ë¹„',
            'ì¸ê±´ë¹„', 'ê°ê°€ìƒê°ë¹„', 'ì˜ì—…ì´ìµ', 'ì˜ì—…ì™¸ìˆ˜ìµ', 'ì˜ì—…ì™¸ë¹„ìš©',
            'ê¸ˆìœµë¹„ìš©', 'ì´ìë¹„ìš©', 'ë‹¹ê¸°ìˆœì´ìµ'
        ]
        
        # íŒŒìƒ í•­ëª© ê³„ì‚° (ëˆ„ë½ëœ í•­ëª© ì¶”ì •)
        calculated_items = self._calculate_derived_items(data)
        data.update(calculated_items)
        
        # ì†ìµê³„ì‚°ì„œ ìƒì„±
        income_statement = []
        for item in standard_items:
            value = data.get(item, 0)
            if value != 0:  # 0ì´ ì•„ë‹Œ ê°’ë§Œ í¬í•¨
                income_statement.append({
                    'êµ¬ë¶„': item,
                    company_name: self._format_amount(value),
                    f'{company_name}_ì›ì‹œê°’': value
                })
        
        # ë¹„ìœ¨ ê³„ì‚° ë° ì¶”ê°€
        ratios = self._calculate_ratios(data)
        for ratio_name, ratio_value in ratios.items():
            income_statement.append({
                'êµ¬ë¶„': ratio_name,
                company_name: f"{ratio_value:.2f}%",
                f'{company_name}_ì›ì‹œê°’': ratio_value
            })
        
        return pd.DataFrame(income_statement)

    def _calculate_derived_items(self, data):
        """íŒŒìƒ í•­ëª© ê³„ì‚° (ëˆ„ë½ëœ ë°ì´í„° ì¶”ì •)"""
        calculated = {}
        
        # ë§¤ì¶œì´ì´ìµ ê³„ì‚°
        if 'ë§¤ì¶œì•¡' in data and 'ë§¤ì¶œì›ê°€' in data:
            calculated['ë§¤ì¶œì´ì´ìµ'] = data['ë§¤ì¶œì•¡'] - data['ë§¤ì¶œì›ê°€']
        elif 'ë§¤ì¶œì•¡' in data and 'ë§¤ì¶œì´ì´ìµ' not in data:
            # ë§¤ì¶œì´ì´ìµì´ ì—†ìœ¼ë©´ ì—…ê³„ í‰ê·  30%ë¡œ ì¶”ì •
            calculated['ë§¤ì¶œì´ì´ìµ'] = data['ë§¤ì¶œì•¡'] * 0.3
            calculated['ë§¤ì¶œì›ê°€'] = data['ë§¤ì¶œì•¡'] - calculated['ë§¤ì¶œì´ì´ìµ']
        elif 'ë§¤ì¶œì´ì´ìµ' in data and 'ë§¤ì¶œì•¡' not in data and 'ë§¤ì¶œì›ê°€' in data:
            calculated['ë§¤ì¶œì•¡'] = data['ë§¤ì¶œì´ì´ìµ'] + data['ë§¤ì¶œì›ê°€']
        
        # íŒê´€ë¹„ ê³„ì‚°
        if 'íŒë§¤ë¹„' in data and 'ê´€ë¦¬ë¹„' in data:
            calculated['íŒê´€ë¹„'] = data['íŒë§¤ë¹„'] + data['ê´€ë¦¬ë¹„']
        elif 'íŒê´€ë¹„' in data and 'íŒë§¤ë¹„' not in data and 'ê´€ë¦¬ë¹„' not in data:
            # íŒê´€ë¹„ë¥¼ 6:4 ë¹„ìœ¨ë¡œ ë¶„í•  (ì¼ë°˜ì  ë¹„ìœ¨)
            calculated['íŒë§¤ë¹„'] = data['íŒê´€ë¹„'] * 0.6
            calculated['ê´€ë¦¬ë¹„'] = data['íŒê´€ë¹„'] * 0.4
        
        # ì˜ì—…ì´ìµ ê³„ì‚°
        if 'ë§¤ì¶œì´ì´ìµ' in data and 'íŒê´€ë¹„' in data and 'ì˜ì—…ì´ìµ' not in data:
            calculated['ì˜ì—…ì´ìµ'] = data['ë§¤ì¶œì´ì´ìµ'] - data['íŒê´€ë¹„']
        
        return calculated

    def _calculate_ratios(self, data):
        """ì£¼ìš” ì¬ë¬´ë¹„ìœ¨ ê³„ì‚°"""
        ratios = {}
        ë§¤ì¶œì•¡ = data.get('ë§¤ì¶œì•¡', 0)
        
        if ë§¤ì¶œì•¡ <= 0:
            return ratios  # ë§¤ì¶œì•¡ì´ ì—†ìœ¼ë©´ ë¹„ìœ¨ ê³„ì‚° ë¶ˆê°€
        
        # ìˆ˜ìµì„± ë¹„ìœ¨
        if 'ì˜ì—…ì´ìµ' in data:
            ratios['ì˜ì—…ì´ìµë¥ (%)'] = round((data['ì˜ì—…ì´ìµ'] / ë§¤ì¶œì•¡) * 100, 2)
        
        if 'ë‹¹ê¸°ìˆœì´ìµ' in data:
            ratios['ìˆœì´ìµë¥ (%)'] = round((data['ë‹¹ê¸°ìˆœì´ìµ'] / ë§¤ì¶œì•¡) * 100, 2)
        
        if 'ë§¤ì¶œì´ì´ìµ' in data:
            ratios['ë§¤ì¶œì´ì´ìµë¥ (%)'] = round((data['ë§¤ì¶œì´ì´ìµ'] / ë§¤ì¶œì•¡) * 100, 2)
        
        # ë¹„ìš© ë¹„ìœ¨
        if 'ë§¤ì¶œì›ê°€' in data:
            ratios['ë§¤ì¶œì›ê°€ìœ¨(%)'] = round((data['ë§¤ì¶œì›ê°€'] / ë§¤ì¶œì•¡) * 100, 2)
        
        if 'íŒê´€ë¹„' in data:
            ratios['íŒê´€ë¹„ìœ¨(%)'] = round((data['íŒê´€ë¹„'] / ë§¤ì¶œì•¡) * 100, 2)
        
        if 'ì¸ê±´ë¹„' in data:
            ratios['ì¸ê±´ë¹„ìœ¨(%)'] = round((data['ì¸ê±´ë¹„'] / ë§¤ì¶œì•¡) * 100, 2)
        
        return ratios

    def _format_amount(self, amount):
        """ê¸ˆì•¡ í¬ë§·íŒ… (í•œêµ­ ë‹¨ìœ„ ì‚¬ìš©)"""
        if amount == 0:
            return "0ì›"
            
        abs_amount = abs(amount)
        sign = "â–¼ " if amount < 0 else ""
        
        if abs_amount >= 1_000_000_000_000:  # 1ì¡° ì´ìƒ
            return f"{sign}{amount/1_000_000_000_000:.1f}ì¡°ì›"
        elif abs_amount >= 100_000_000:  # 1ì–µ ì´ìƒ
            return f"{sign}{amount/100_000_000:.0f}ì–µì›"
        elif abs_amount >= 10_000:  # 1ë§Œ ì´ìƒ
            return f"{sign}{amount/10_000:.0f}ë§Œì›"
        else:
            return f"{sign}{amount:,.0f}ì›"

    def merge_company_data(self, dataframes):
        """ì—¬ëŸ¬ íšŒì‚¬ ë°ì´í„° ë³‘í•© (ì•ˆì „í•œ ë³‘í•©)"""
        if not dataframes:
            return pd.DataFrame()
        
        if len(dataframes) == 1:
            return dataframes[0]
        
        # ê¸°ì¤€ì´ ë˜ëŠ” ì²« ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„
        merged = dataframes[0].copy()
        
        # ë‚˜ë¨¸ì§€ ë°ì´í„°í”„ë ˆì„ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ë³‘í•©
        for df in dataframes[1:]:
            try:
                # íšŒì‚¬ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (êµ¬ë¶„, _ì›ì‹œê°’ ì»¬ëŸ¼ ì œì™¸)
                company_cols = [col for col in df.columns 
                              if col != 'êµ¬ë¶„' and not col.endswith('_ì›ì‹œê°’')]
                
                for company_col in company_cols:
                    # êµ¬ë¶„ì„ ì¸ë±ìŠ¤ë¡œ í•˜ì—¬ ë°ì´í„° ë³‘í•©
                    company_data = df.set_index('êµ¬ë¶„')[company_col]
                    merged_temp = merged.set_index('êµ¬ë¶„')
                    merged_temp = merged_temp.join(company_data, how='outer')
                    merged = merged_temp.reset_index()
            except Exception as e:
                st.warning(f"âš ï¸ ë°ì´í„° ë³‘í•© ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ê²°ì¸¡ì¹˜ë¥¼ "-"ë¡œ ì±„ì›€
        merged = merged.fillna("-")
        
        return merged

    def create_comparison_report(self, merged_df):
        """ê²½ìŸì‚¬ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"""
        if merged_df is None or merged_df.empty:
            return "ğŸ“‹ ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ğŸ“Š XBRL ì†ìµê³„ì‚°ì„œ ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„")
        report_lines.append("=" * 80)
        
        # ê¸°ë³¸ ì •ë³´
        companies = [col for col in merged_df.columns 
                    if col != 'êµ¬ë¶„' and not col.endswith('_ì›ì‹œê°’')]
        report_lines.append(f"ğŸ“ˆ ë¶„ì„ ëŒ€ìƒ íšŒì‚¬: {', '.join(companies)}")
        report_lines.append(f"ğŸ“‹ ë¶„ì„ í•­ëª© ìˆ˜: {len(merged_df)}ê°œ")
        report_lines.append("")
        
        # ì£¼ìš” ìˆ˜ìµì„± ì§€í‘œ í•˜ì´ë¼ì´íŠ¸
        profit_rows = merged_df[merged_df['êµ¬ë¶„'].str.contains('ì´ìµë¥ |ë¹„ìœ¨', na=False)]
        
        if not profit_rows.empty:
            report_lines.append("ğŸ¯ ì£¼ìš” ìˆ˜ìµì„± ì§€í‘œ ë¹„êµ")
            report_lines.append("-" * 50)
            
            for _, row in profit_rows.iterrows():
                êµ¬ë¶„ = row['êµ¬ë¶„']
                values = []
                for company in companies:
                    value = row.get(company, "-")
                    if value != "-":
                        values.append(f"{company}: {value}")
                
                if values:
                    report_lines.append(f"â€¢ {êµ¬ë¶„}")
                    report_lines.append(f"  {' | '.join(values)}")
            
            report_lines.append("")
        
        # ì ˆëŒ“ê°’ ë°ì´í„° ìš”ì•½
        absolute_rows = merged_df[~merged_df['êµ¬ë¶„'].str.contains('ë¥ |ë¹„ìœ¨', na=False)]
        if not absolute_rows.empty:
            report_lines.append("ğŸ’° ì£¼ìš” ì ˆëŒ“ê°’ ì§€í‘œ")
            report_lines.append("-" * 50)
            
            key_items = ['ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ']
            for item in key_items:
                item_row = absolute_rows[absolute_rows['êµ¬ë¶„'] == item]
                if not item_row.empty:
                    values = []
                    for company in companies:
                        value = item_row.iloc[0].get(company, "-")
                        if value != "-":
                            values.append(f"{company}: {value}")
                    
                    if values:
                        report_lines.append(f"â€¢ {item}")
                        report_lines.append(f"  {' | '.join(values)}")
        
        report_lines.append("")
        report_lines.append("ğŸ’¡ ì´ ë¶„ì„ì€ ì—…ë¡œë“œëœ XBRL íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        report_lines.append("ğŸ“Š ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ì›ë³¸ ì¬ë¬´ì œí‘œì™€ ëŒ€ì¡°í•˜ì—¬ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        return "\n".join(report_lines)
        

# ==========================
# ìˆ˜ë™ XBRL ì—…ë¡œë“œìš© ì¬ë¬´ë°ì´í„° í”„ë¡œì„¸ì„œ (ê°œì„ ëœ ë²„ì „)
# ==========================

class SKFinancialDataProcessor:
    INCOME_STATEMENT_MAP = {
        'sales': 'ë§¤ì¶œì•¡',
        'revenue': 'ë§¤ì¶œì•¡',
        'ë§¤ì¶œì•¡': 'ë§¤ì¶œì•¡',
        'ìˆ˜ìµ(ë§¤ì¶œì•¡)': 'ë§¤ì¶œì•¡',
        'costofgoodssold': 'ë§¤ì¶œì›ê°€',
        'cogs': 'ë§¤ì¶œì›ê°€',
        'costofrevenue': 'ë§¤ì¶œì›ê°€',
        'ë§¤ì¶œì›ê°€': 'ë§¤ì¶œì›ê°€',
        'operatingexpenses': 'íŒê´€ë¹„',
        'sellingexpenses': 'íŒë§¤ë¹„',
        'administrativeexpenses': 'ê´€ë¦¬ë¹„',
        'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„': 'íŒê´€ë¹„',
        'íŒê´€ë¹„': 'íŒê´€ë¹„',
        'grossprofit': 'ë§¤ì¶œì´ì´ìµ',
        'ë§¤ì¶œì´ì´ìµ': 'ë§¤ì¶œì´ì´ìµ',
        'operatingincome': 'ì˜ì—…ì´ìµ',
        'operatingprofit': 'ì˜ì—…ì´ìµ',
        'ì˜ì—…ì´ìµ': 'ì˜ì—…ì´ìµ',
        'netincome': 'ë‹¹ê¸°ìˆœì´ìµ',
        'ë‹¹ê¸°ìˆœì´ìµ': 'ë‹¹ê¸°ìˆœì´ìµ',
    }
    
    def __init__(self):
        self.company_data = {}
        self.sk_company = "SKì—ë„ˆì§€"
        self.competitors = ["GSì¹¼í…ìŠ¤", "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "S-Oil"]

    def process_dart_data(self, dart_df, company_name):
        """DART APIì—ì„œ ë°›ì€ DataFrameì„ í‘œì¤€ ì†ìµê³„ì‚°ì„œë¡œ ë³€í™˜"""
        try:
            if dart_df.empty:
                return None
            
# ë””ë²„ê¹…: ì›ë³¸ DART ë°ì´í„° ë¡œê¹…
            st.write(f"ğŸ” {company_name} ì›ë³¸ DART ë°ì´í„° ({len(dart_df)}ê°œ í•­ëª©):")
            debug_df = dart_df[['account_nm', 'thstrm_amount']].head(10)
            st.dataframe(debug_df, use_container_width=True)

            financial_data = {}
            processed_count = 0
            
            for _, row in dart_df.iterrows():
                account_nm = row.get('account_nm', '')
                thstrm_amount = row.get('thstrm_amount', '0')
                
                # ë¹ˆ ê°’ ê±´ë„ˆë›°ê¸°
                if not account_nm or not thstrm_amount:
                    continue
                        
                try:
                    # ë§ˆì´ë„ˆìŠ¤ ê°’ ì •í™• ì²˜ë¦¬
                    amount_str = str(thstrm_amount).replace(',', '')
                    if '(' in amount_str and ')' in amount_str:
                        # ê´„í˜¸ë¡œ í‘œì‹œëœ ë§ˆì´ë„ˆìŠ¤
                        amount_str = '-' + amount_str.replace('(', '').replace(')', '')
                    value = float(amount_str) if amount_str != '-' else 0
                    
                    # DART APIëŠ” ì²œì› ë‹¨ìœ„ë¡œ ì œê³µí•˜ë¯€ë¡œ ì–µì› ë‹¨ìœ„ë¡œ ë³€í™˜
                    value = value / 100_000  # ì²œì› â†’ ì–µì› ë³€í™˜
                    
                except (ValueError, TypeError):
                    continue

                # ê³„ì •ê³¼ëª© ë§¤í•‘
                mapped = False
                for key, mapped_name in self.INCOME_STATEMENT_MAP.items():
                    if key in account_nm or account_nm in key:
                        if mapped_name not in financial_data or abs(value) > abs(financial_data[mapped_name]):
                            financial_data[mapped_name] = value
                            mapped = True
                        break
                
                if mapped:
                    processed_count += 1

            # ë””ë²„ê¹…: ë§¤í•‘ëœ ì¬ë¬´ ë°ì´í„° ë¡œê¹…
            st.write(f"ğŸ“Š {company_name} ë§¤í•‘ëœ ì¬ë¬´ ë°ì´í„° ({processed_count}ê°œ ì²˜ë¦¬):")
            for key, value in financial_data.items():
                st.write(f"  {key}: {value:,.0f}ì–µì›")

            # ë°ì´í„° ê²€ì¦
            if not financial_data:
                st.error(f"âŒ {company_name}: ë§¤í•‘ëœ ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None

            return self._create_income_statement(financial_data, company_name)
            
        except Exception as e:
            st.error(f"DART ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None

    def _create_income_statement(self, data, company_name):
        """í‘œì¤€ ì†ìµê³„ì‚°ì„œ êµ¬ì¡° ìƒì„±"""
        standard_items = [
            'ë§¤ì¶œì•¡', 'ë§¤ì¶œì›ê°€', 'ë§¤ì¶œì´ì´ìµ', 'íŒë§¤ë¹„', 'ê´€ë¦¬ë¹„', 'íŒê´€ë¹„',
            'ì¸ê±´ë¹„', 'ê°ê°€ìƒê°ë¹„', 'ì˜ì—…ì´ìµ', 'ì˜ì—…ì™¸ìˆ˜ìµ', 'ì˜ì—…ì™¸ë¹„ìš©',
            'ê¸ˆìœµë¹„ìš©', 'ì´ìë¹„ìš©', 'ë‹¹ê¸°ìˆœì´ìµ'
        ]
        
        calculated_items = self._calculate_derived_items(data)
        data.update(calculated_items)
        
        income_statement = []
        for item in standard_items:
            value = data.get(item, 0)
            if value != 0:
                if item in ['ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ']:
                    formatted_value = self._format_amount_with_loss_indicator(value)
                else:
                    formatted_value = self._format_amount_profit(value)
                
                income_statement.append({
                    'êµ¬ë¶„': item,
                    company_name: formatted_value,
                    f'{company_name}_ì›ì‹œê°’': value
                })
        
        ratios = self._calculate_enhanced_ratios(data)
        for ratio_name, ratio_value in ratios.items():
            if ratio_name == 'ë§¤ì¶œ 1ì¡°ì›ë‹¹ ì˜ì—…ì´ìµ(ì–µì›)':
                display_value = f"{ratio_value:.2f}ì–µì›"
            elif ratio_name.endswith('(%)'):
                display_value = f"{ratio_value:.2f}%"
            else:
                display_value = f"{ratio_value:.2f}ì "
            
            income_statement.append({
                'êµ¬ë¶„': ratio_name,
                company_name: display_value,
                f'{company_name}_ì›ì‹œê°’': ratio_value
            })
        
        return pd.DataFrame(income_statement)

    def _calculate_derived_items(self, data):
        calculated = {}
        if 'ë§¤ì¶œì•¡' in data and 'ë§¤ì¶œì›ê°€' in data:
            calculated['ë§¤ì¶œì´ì´ìµ'] = data['ë§¤ì¶œì•¡'] - data['ë§¤ì¶œì›ê°€']
        elif 'ë§¤ì¶œì•¡' in data and 'ë§¤ì¶œì´ì´ìµ' not in data:
            calculated['ë§¤ì¶œì´ì´ìµ'] = data['ë§¤ì¶œì•¡'] * 0.3
            calculated['ë§¤ì¶œì›ê°€'] = data['ë§¤ì¶œì•¡'] - calculated['ë§¤ì¶œì´ì´ìµ']
        
        if 'íŒë§¤ë¹„' in data and 'ê´€ë¦¬ë¹„' in data:
            calculated['íŒê´€ë¹„'] = data['íŒë§¤ë¹„'] + data['ê´€ë¦¬ë¹„']
        
        return calculated

    def _calculate_enhanced_ratios(self, data):
        ratios = {}
        ë§¤ì¶œì•¡ = data.get('ë§¤ì¶œì•¡', 0)
        
        if ë§¤ì¶œì•¡ > 0:
            if 'ì˜ì—…ì´ìµ' in data:
                ratios['ì˜ì—…ì´ìµë¥ (%)'] = round((data['ì˜ì—…ì´ìµ'] / ë§¤ì¶œì•¡) * 100, 2)
            if 'ë‹¹ê¸°ìˆœì´ìµ' in data:
                ratios['ìˆœì´ìµë¥ (%)'] = round((data['ë‹¹ê¸°ìˆœì´ìµ'] / ë§¤ì¶œì•¡) * 100, 2)
            if 'ë§¤ì¶œì›ê°€' in data:
                ratios['ë§¤ì¶œì›ê°€ìœ¨(%)'] = round((data['ë§¤ì¶œì›ê°€'] / ë§¤ì¶œì•¡) * 100, 2)
            if 'íŒê´€ë¹„' in data:
                ratios['íŒê´€ë¹„ìœ¨(%)'] = round((data['íŒê´€ë¹„'] / ë§¤ì¶œì•¡) * 100, 2)
            if 'ì˜ì—…ì´ìµ' in data:
                ratios['ë§¤ì¶œ 1ì¡°ì›ë‹¹ ì˜ì—…ì´ìµ(ì–µì›)'] = round((data['ì˜ì—…ì´ìµ'] / 100_000_000) / (ë§¤ì¶œì•¡ / 1_000_000_000_000), 2)
            
            ratios['ì›ê°€íš¨ìœ¨ì„±ì§€ìˆ˜(ì )'] = round(100 - ratios.get('ë§¤ì¶œì›ê°€ìœ¨(%)', 0), 2)
            operating_margin = ratios.get('ì˜ì—…ì´ìµë¥ (%)', 0)
            net_margin = ratios.get('ìˆœì´ìµë¥ (%)', 0)
            ratios['ì¢…í•©ìˆ˜ìµì„±ì ìˆ˜(ì )'] = round((operating_margin * 2 + net_margin) / 3, 2)
            
            industry_avg_margin = 3.5
            if operating_margin > 0:
                ratios['ì—…ê³„ëŒ€ë¹„ì„±ê³¼(%)'] = round((operating_margin / industry_avg_margin) * 100, 2)
        
        return ratios

    def _format_amount_with_loss_indicator(self, amount):
        if amount < 0:
            abs_amount = abs(amount)
            if abs_amount >= 1_000_000_000_000:
                return f"â–¼ {abs_amount/1_000_000_000_000:.1f}ì¡°ì› ì˜ì—…ì†ì‹¤"
            elif abs_amount >= 100_000_000:
                return f"â–¼ {abs_amount/100_000_000:.0f}ì–µì› ì˜ì—…ì†ì‹¤"
            elif abs_amount >= 10_000:
                return f"â–¼ {abs_amount/10_000:.0f}ë§Œì› ì˜ì—…ì†ì‹¤"
            else:
                return f"â–¼ {abs_amount:,.0f}ì› ì˜ì—…ì†ì‹¤"
        else:
            return self._format_amount_profit(amount)

    def _format_amount_profit(self, amount):
        if abs(amount) >= 1_000_000_000_000:
            return f"{amount/1_000_000_000_000:.1f}ì¡°ì›"
        elif abs(amount) >= 100_000_000:
            return f"{amount/100_000_000:.0f}ì–µì›"
        elif abs(amount) >= 10_000:
            return f"{amount/10_000:.0f}ë§Œì›"
        else:
            return f"{amount:,.0f}ì›"

    def merge_company_data(self, dataframes):
        if not dataframes:
            return pd.DataFrame()
        
        sk_df = None
        other_dfs = []
        
        for df in dataframes:
            if any(self.sk_company in col for col in df.columns):
                sk_df = df.copy()
            else:
                other_dfs.append(df)
        
        if sk_df is not None:
            merged = sk_df.copy()
            dataframes_to_merge = other_dfs
        else:
            merged = dataframes[0].copy()
            dataframes_to_merge = dataframes[1:]
        
        for df in dataframes_to_merge:
            company_cols = [col for col in df.columns if col != 'êµ¬ë¶„' and not col.endswith('_ì›ì‹œê°’')]
            for company_col in company_cols:
                company_data = df.set_index('êµ¬ë¶„')[company_col]
                merged = merged.set_index('êµ¬ë¶„').join(company_data, how='outer').reset_index()
        
        merged = merged.fillna("-")
        
        cols = ['êµ¬ë¶„']
        sk_cols = [col for col in merged.columns if self.sk_company in col and not col.endswith('_ì›ì‹œê°’')]
        competitor_cols = [col for col in merged.columns if col not in cols + sk_cols and not col.endswith('_ì›ì‹œê°’')]
        final_cols = cols + sk_cols + competitor_cols
        
        raw_value_cols = [col for col in merged.columns if col.endswith('_ì›ì‹œê°’')]
        final_cols.extend(raw_value_cols)
        
        merged = merged[final_cols]
        return merged

# ==========================
# êµ¬ê¸€ì‹œíŠ¸ + RSS í†µí•© ë‰´ìŠ¤ ìˆ˜ì§‘ í´ë˜ìŠ¤ (ê°œì„ )
# ==========================

# -*- coding: utf-8 -*-


import os
import re
import json
from datetime import datetime
from typing import Dict, List, Union

import pandas as pd
import feedparser

# ì„ íƒ ì˜ì¡´ì„± â€“ ì„¤ì¹˜ë¼ ìˆì§€ ì•Šìœ¼ë©´ Google Sheets ê¸°ëŠ¥ë§Œ ë¹„í™œì„±í™”
try:
    import gspread
    from google.oauth2.service_account import Credentials
    _GSPREAD_AVAILABLE = True
except ImportError:  # ì„œë²„ì— gspread ê°€ ì—†ì„ ìˆ˜ë„ ìˆìŒ
    _GSPREAD_AVAILABLE = False

# Plotly ê°™ì€ ì‹œê°í™”ëŠ” ì™¸ë¶€ì—ì„œ ì“°ë¯€ë¡œ ì´ê³³ì—ì„  í•„ìš” ì—†ìŒ
# ---------------------------------------------------------------------
class SKNewsCollector:
    """
    SK ì—ë„ˆì§€ & êµ­ë‚´ ì •ìœ ì—…ê³„ ì „ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°
    ì‚¬ìš©ë²•
    -----
    collector = SKNewsCollector(
        sheet_id="16g1G89xâ€¦",                         # í•„ìˆ˜ X
        service_account_json="service_key.json"       # ë˜ëŠ” dict / ENV
    )
    df = collector.collect_news(max_items_per_feed=30)
    """

    # RSS í”¼ë“œ -----------------
    DEFAULT_RSS: Dict[str, str] = {
        "ì—°í•©ë‰´ìŠ¤_ê²½ì œ":   "https://www.yna.co.kr/rss/economy.xml",
        "ì¡°ì„ ì¼ë³´_ê²½ì œ":   "https://www.chosun.com/arc/outboundfeeds/rss/category/economy/",
        "í•œêµ­ê²½ì œ":       "https://www.hankyung.com/feed/economy",
        "ì„œìš¸ê²½ì œ":       "https://www.sedaily.com/RSSFeed.xml",
        "ë§¤ì¼ê²½ì œ":       "https://www.mk.co.kr/rss/30000001/",
        "ì´ë°ì¼ë¦¬":       "https://www.edaily.co.kr/rss/rss_economy.xml",
        "ì•„ì‹œì•„ê²½ì œ":     "https://rss.asiae.co.kr/economy.xml",
        "íŒŒì´ë‚¸ì…œë‰´ìŠ¤":   "https://www.fnnews.com/rss/fn_realestate_all.xml",
    }

    # í‚¤ì›Œë“œ -------------------
    OIL_KEYWORDS: List[str] = [
        # SK ê³„ì—´
        "SK", "SKì—ë„ˆì§€", "SKì´ë…¸ë² ì´ì…˜", "SKì˜¨", "SKê·¸ë£¹",
        # ê²½ìŸì‚¬
        "GSì¹¼í…ìŠ¤", "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "í˜„ëŒ€ì˜¤ì¼ë±…í¬", "S-Oil", "ì—ì“°ì˜¤ì¼",
        # ì‚°ì—…/ì‹œì¥
        "ì •ìœ ", "ìœ ê°€", "ì›ìœ ", "ì„ìœ ", "í™”í•™", "ì—ë„ˆì§€", "ë‚˜í”„íƒ€",
        "íœ˜ë°œìœ ", "ê²½ìœ ", "ë“±ìœ ", "ì¤‘ìœ ", "ì„ìœ í™”í•™", "ì •ì œ", "ì •ì œë§ˆì§„",
        "WTI", "ë‘ë°”ì´ìœ ", "ë¸Œë ŒíŠ¸ìœ ",
        # ì¬ë¬´/ì‹¤ì 
        "ì˜ì—…ì´ìµ", "ìˆœì´ìµ", "ë§¤ì¶œ", "ì‹¤ì ", "ì†ì‹¤", "í‘ì", "ì ì",
        "ìˆ˜ìµì„±", "ë§ˆì§„", "íˆ¬ì", "ì„¤ë¹„",
        # ì •ì±…Â·í™˜ê²½
        "íƒ„ì†Œì¤‘ë¦½", "ESG", "ì¹œí™˜ê²½", "ìˆ˜ì†Œ", "ì‹ ì¬ìƒì—ë„ˆì§€",
    ]

    # -----------------------------------------------------------------
    def __init__(
        self,
        sheet_id: str | None = None,
        service_account_json: Union[str, Dict, None] = None,
        rss_feeds: Dict[str, str] | None = None,
    ) -> None:
        self.sheet_id = sheet_id                # ì—†ìœ¼ë©´ Google Sheets ê¸°ëŠ¥ ìƒëµ
        self.service_account_json = service_account_json
        self.rss_feeds = rss_feeds or self.DEFAULT_RSS.copy()

    # =========================  PUBLIC API  =========================
    def collect_news(self, *, max_items_per_feed: int = 25) -> pd.DataFrame:
        """
        Google Sheets + RSSì—ì„œ ë‰´ìŠ¤ë¥¼ ëª¨ì•„ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë°˜í™˜
        """
        df_sheets = self._fetch_sheet_news()           # ì‹¤íŒ¨í•´ë„ ë¹ˆ DF
        df_rss    = self._fetch_rss_news(max_items=max_items_per_feed)

        if df_sheets.empty and df_rss.empty:
            return pd.DataFrame()

        df_all = pd.concat([df_sheets, df_rss], ignore_index=True)
        df_all.drop_duplicates(subset="ì œëª©", inplace=True)
        df_all.sort_values(["SKê´€ë ¨ë„", "ì˜í–¥ë„"], ascending=[False, False], inplace=True)
        df_all.reset_index(drop=True, inplace=True)
        return df_all

    # =======================  GOOGLE SHEETS  ========================
    def _fetch_sheet_news(self) -> pd.DataFrame:
        """
        Google Sheetsì—ì„œ ê¸°ì‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        - gspread ê°€ ì—†ê±°ë‚˜ ì¸ì¦ ì‹¤íŒ¨ ì‹œ ë¹ˆ DF ë°˜í™˜
        - service_account_json ìš°ì„  â†’ í™˜ê²½ë³€ìˆ˜ JSON(NEWS_SVC_KEY) ëŒ€ì²´ í—ˆìš©
        """
        if not _GSPREAD_AVAILABLE or not self.sheet_id:
            return pd.DataFrame()

        # ---- ì¸ì¦ ì •ë³´ í™•ë³´ ---------------------------------------
        key_payload: Dict | None = None
        if isinstance(self.service_account_json, dict):
            key_payload = self.service_account_json
        elif isinstance(self.service_account_json, str):
            # ê²½ë¡œì¼ ìˆ˜ë„, JSON ë¬¸ìì—´ì¼ ìˆ˜ë„
            if os.path.exists(self.service_account_json):
                with open(self.service_account_json, "r", encoding="utf-8") as f:
                    key_payload = json.load(f)
            else:
                try:
                    key_payload = json.loads(self.service_account_json)
                except json.JSONDecodeError:
                    pass
        elif os.getenv("NEWS_SVC_KEY"):                   # í™˜ê²½ë³€ìˆ˜ ì§€ì›
            key_payload = json.loads(os.getenv("NEWS_SVC_KEY"))

        if not key_payload:
            # ì¸ì¦ ì •ë³´ë¥¼ ëª» ì°¾ìœ¼ë©´ Google Sheets ê¸°ëŠ¥ ë¬´ì‹œ
            return pd.DataFrame()

        try:
            creds = Credentials.from_service_account_info(
                key_payload,
                scopes=[
                    "https://www.googleapis.com/auth/spreadsheets.readonly",
                    "https://www.googleapis.com/auth/drive.readonly",
                ],
            )
            gc = gspread.authorize(creds)
            worksheet = gc.open_by_key(self.sheet_id).sheet1
            rows = worksheet.get_all_records()  # list[dict]
            if not rows:
                return pd.DataFrame()

            df = pd.DataFrame(rows)
        except Exception:
            return pd.DataFrame()

        # ---- ì»¬ëŸ¼ ì •ê·œí™” ------------------------------------------
        df.columns = df.columns.str.strip()

        rename_map = {}
        for col in df.columns:
            low = col.lower()
            if any(k in low for k in ("title", "ì œëª©")):
                rename_map[col] = "ì œëª©"
            elif any(k in low for k in ("url", "link", "ë§í¬")):
                rename_map[col] = "URL"
            elif any(k in low for k in ("content", "summary", "ë‚´ìš©", "ìš”ì•½")):
                rename_map[col] = "ìš”ì•½"
            elif any(k in low for k in ("date", "ë‚ ì§œ", "time", "ì‹œê°")):
                rename_map[col] = "ë‚ ì§œ"
            elif any(k in low for k in ("source", "ì–¸ë¡ ", "ì¶œì²˜")):
                rename_map[col] = "ì¶œì²˜"

        df.rename(columns=rename_map, inplace=True)
        if "ì œëª©" not in df.columns:
            df.rename(columns={df.columns[0]: "ì œëª©"}, inplace=True)

        # í•„ìˆ˜ ì»¬ëŸ¼ ê¸°ë³¸ê°’
        for col, default in (
            ("URL", ""),
            ("ìš”ì•½", df["ì œëª©"]),
            ("ë‚ ì§œ", datetime.now().strftime("%Y-%m-%d %H:%M")),
            ("ì¶œì²˜", "GoogleSheet"),
        ):
            if col not in df.columns:
                df[col] = default

        df = df[df["ì œëª©"].astype(str).str.strip() != ""].copy()
        return self._enrich_dataframe(df)

    # ===========================  RSS  ==============================
    def _fetch_rss_news(self, *, max_items: int = 25) -> pd.DataFrame:
        collected: List[Dict] = []

        for source, url in self.rss_feeds.items():
            try:
                feed = feedparser.parse(url)
            except Exception:
                continue

            for entry in feed.entries[:max_items]:
                title = entry.get("title", "").strip()
                if not title:
                    continue

                summary = entry.get("summary", entry.get("description", ""))
                published = entry.get("published", "")
                link = entry.get("link", "")

                record = {
                    "ì œëª©": title,
                    "ìš”ì•½": summary,
                    "ë‚ ì§œ": self._parse_date(published),
                    "URL": link,
                    "ì¶œì²˜": source,
                }
                collected.append(record)

        if not collected:
            return pd.DataFrame()
        df = pd.DataFrame(collected)
        return self._enrich_dataframe(df)

    # ======================  POST-PROCESSING  =======================
    def _enrich_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        â€¢ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ 'í‚¤ì›Œë“œ'
        â€¢ ì˜í–¥ë„ / SKê´€ë ¨ë„ ìŠ¤ì½”ì–´ ê³„ì‚°
        â€¢ íšŒì‚¬ ì¶”ì • & ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        """
        df["í‚¤ì›Œë“œ"] = df["ì œëª©"].apply(self._extract_keywords)
        df["ì¤‘ìš”ë„"] = df["ì œëª©"].apply(self._calc_importance)
        df["íšŒì‚¬"]   = df["ì œëª©"].apply(self._extract_company)
        df["ì¹´í…Œê³ ë¦¬"] = df["ì œëª©"].apply(self._classify_category)
        df["SKê´€ë ¨ë„"] = df["ì œëª©"].apply(self._calc_sk_relevance)
        df["ì˜í–¥ë„"] = df["ì¤‘ìš”ë„"]
        return df

    # -----------------  util: keyword / scoring  --------------------
    def _extract_keywords(self, text: str) -> str:
        if not isinstance(text, str):
            return ""
        kws = [kw for kw in self.OIL_KEYWORDS if kw.lower() in text.lower()]
        return ", ".join(kws[:5]) if kws else ""

    def _calc_importance(self, text: str) -> int:
        if not isinstance(text, str):
            return 0
        core = ["SK", "ì˜ì—…ì´ìµ", "ì‹¤ì ", "ì†ì‹¤", "íˆ¬ì", "í•©ë³‘"]
        score = sum(2 for w in core if w.lower() in text.lower())
        return min(score + 3, 10)

    def _calc_sk_relevance(self, text: str) -> int:
        if not isinstance(text, str):
            return 0
        text_l = text.lower()
        score = 5 if "sk" in text_l else 0
        score += 3 if "skì—ë„ˆì§€" in text_l else 0
        if any(w in text_l for w in ("ì •ìœ ", "ì„ìœ ", "í™”í•™")):
            score += 2
        return min(score, 10)

    def _extract_company(self, text: str) -> str:
        if not isinstance(text, str):
            return "ê¸°íƒ€"
        companies = ["SKì—ë„ˆì§€", "SK", "GSì¹¼í…ìŠ¤",
                     "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "S-Oil", "ì—ì“°ì˜¤ì¼"]
        for c in companies:
            if c.lower() in text.lower():
                return c
        return "ê¸°íƒ€"

    def _classify_category(self, text: str) -> str:
        s = text.lower() if isinstance(text, str) else ""
        if any(k in s for k in ("sk", "skì—ë„ˆì§€", "skì´ë…¸ë² ì´ì…˜")):
            return "SKê´€ë ¨"
        if any(k in s for k in ("ì†ì‹¤", "ì ì", "ë¹„ìš©", "ì›ê°€", "ë³´ìˆ˜", "ì¤‘ë‹¨")):
            return "ë¹„ìš©ì ˆê°"
        if any(k in s for k in ("ì˜ì—…ì´ìµ", "ë§¤ì¶œ", "ìˆ˜ìµ", "í‘ì", "ì¦ê°€", "ì„±ì¥")):
            return "ìˆ˜ìµê°œì„ "
        if any(k in s for k in ("íˆ¬ì", "ì„¤ë¹„", "ê³µì¥", "ESG", "ìˆ˜ì†Œ", "í™•ì¥")):
            return "ì „ëµë³€í™”"
        return "ì™¸ë¶€í™˜ê²½"

    @staticmethod
    def _parse_date(date_str: str) -> str:
        from dateutil import parser
        try:
            return parser.parse(date_str).strftime("%Y-%m-%d %H:%M")
        except Exception:
            return datetime.now().strftime("%Y-%m-%d %H:%M")




# ==========================
# Gemini AI ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸°
# ==========================

class GeminiInsightGenerator:
    def __init__(self, api_key=GEMINI_API_KEY):
        if GEMINI_AVAILABLE and api_key:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
        else:
            self.model = None

    def generate_financial_insight(self, financial_data):
        """ì¬ë¬´ë°ì´í„° â†’ ê²½ìŸì‚¬ ë¶„ì„ ì¸ì‚¬ì´íŠ¸"""
        if not self.model:
            return "Gemini APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        try:
            # ì¬ë¬´ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            data_str = financial_data.to_string() if hasattr(financial_data, 'to_string') else str(financial_data)
            
            prompt = f"""
ë‹¤ìŒì€ SKì—ë„ˆì§€ ì¤‘ì‹¬ì˜ ì¬ë¬´ë°ì´í„°ì…ë‹ˆë‹¤:

{data_str}

ë‹¹ì‹ ì€ SKì—ë„ˆì§€ ë‚´ë¶€ ì „ëµê¸°íšíŒ€ ì†Œì†ìœ¼ë¡œ,
ê²½ìŸì‚¬ ëŒ€ë¹„ SKì—ë„ˆì§€ì˜ **ì¬ë¬´ ë° ì‚¬ì—… ê²½ìŸë ¥**ì„ ë¶„ì„í•˜ì—¬
í–¥í›„ **ì‚¬ì—… ì „ëµ ìˆ˜ë¦½ ë° ê°œì„  ë°©í–¥**ì„ ë„ì¶œí•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

ë‹¤ìŒ í•­ëª©ì— ë§ì¶° **ì „ëµì  ì¸ì‚¬ì´íŠ¸**ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:

## 1. ğŸ“Š SKì—ë„ˆì§€ í˜„ì¬ ì¬ë¬´ ìƒí™© ë¶„ì„
- ìµœê·¼ ìˆ˜ìµì„± ë³€í™”ì™€ ì›ì¸ ì§„ë‹¨
- ê²½ìŸì‚¬(GSì¹¼í…ìŠ¤ ë“±) ëŒ€ë¹„ ìˆ˜ìµêµ¬ì¡°ì˜ ê°•ì /ì•½ì 
- ì˜ì—…ì´ìµë¥ , ìˆœì´ìµë¥ , ì›ê°€ìœ¨, íŒê´€ë¹„ìœ¨ ë“± ì£¼ìš” ì§€í‘œ ë¹„êµ

## 2. ğŸ” ê²½ìŸì‚¬ ëŒ€ë¹„ ì‚¬ì—… ê²½ìŸë ¥ ë¶„ì„
- ê²½ìŸì‚¬ ëŒ€ë¹„ ì›ê°€ íš¨ìœ¨ì„±, ìˆ˜ìµì„±, ë¹„ìš© êµ¬ì¡° ì°¨ì´
- SKì—ë„ˆì§€ê°€ ê°œì„ í•˜ê±°ë‚˜ ê°•í™”í•  ìˆ˜ ìˆëŠ” í¬ì¸íŠ¸ ë„ì¶œ

## 3. ğŸ§© ì „ëµì  ì‹œì‚¬ì  ë° ë‚´ë¶€ ê°œì„  ë°©í–¥
- ë‹¨ê¸°ì ìœ¼ë¡œ ì¬ë¬´ ê°œì„ ì„ ìœ„í•´ ìš°ì„  ê²€í† í•´ì•¼ í•  ì˜ì—­
- ì¤‘ì¥ê¸°ì ìœ¼ë¡œ ê²½ìŸë ¥ì„ ë†’ì´ê¸° ìœ„í•œ ì¡°ì§ ì°¨ì›ì˜ ì „ëµ ì œì–¸

## 4. ğŸ“Œ ë¦¬ìŠ¤í¬ ìš”ì¸ ë° ê°ì‹œ í•­ëª©
- í˜„ì¬ ê°€ì¥ í° ì¬ë¬´ì /ì‚¬ì—…ì  ë¦¬ìŠ¤í¬
- ì™¸ë¶€í™˜ê²½(ìœ ê°€, ì •ì±… ë“±)ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ ë¯¼ê°ë„
- ë‚´ë¶€ì ìœ¼ë¡œ ë°˜ë“œì‹œ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  ì£¼ìš” ì§€í‘œ

## 5. ğŸš€ í–¥í›„ 6ê°œì›” ë‚´ ì‹¤ì§ˆì  ì•¡ì…˜ í”Œëœ ì œì•ˆ
- ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ë¶€ ì¡°ì¹˜ 3~5ê°€ì§€ ì œì•ˆ
- KPI ê¸°ì¤€ ì¬ì„¤ì • ë˜ëŠ” ëª©í‘œ ì¬ì •ì˜ í•„ìš” ì—¬ë¶€

ë¶„ì„ì€ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ ìˆ˜ì¤€ìœ¼ë¡œ í•´ì£¼ì‹œë˜, ì‹¤ë¬´ìê°€ ë°”ë¡œ ë³´ê³  ì‹¤í–‰ë°©ì•ˆì„ ë§Œë“¤ ìˆ˜ ìˆì„ ì •ë„ë¡œ êµ¬ì²´ì ì´ê³  í˜„ì‹¤ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
"""

            response = self.model.generate_content(prompt)
            return response.text
        
        except Exception as e:
            return f"AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def generate_news_insight(self, news_keywords, news_samples):
        """ë‰´ìŠ¤ë°ì´í„° â†’ ë™ì  ì‹œì¥ ì¸ì‚¬ì´íŠ¸"""
        if not self.model:
            return "Gemini APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        try:
            keywords_text = ', '.join(news_keywords[:10]) if news_keywords else 'í‚¤ì›Œë“œ ì—†ìŒ'
            samples_text = str(news_samples[:3]) if news_samples else 'ë‰´ìŠ¤ ì—†ìŒ'
            
            prompt = f"""
SKì—ë„ˆì§€ ê´€ë ¨ ë‰´ìŠ¤ ë¶„ì„:

ì£¼ìš” í‚¤ì›Œë“œ: {keywords_text}
ë‰´ìŠ¤ ìƒ˜í”Œ: {samples_text}

**ë™ì  ì‹œì¥ ì¸ì‚¬ì´íŠ¸**ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

## 1. ğŸ“Š í˜„ì¬ ì‹œì¥ ìƒí™© ì§„ë‹¨
- ì •ìœ ì—…ê³„ ì „ë°˜ì  ë™í–¥
- SKì—ë„ˆì§€ ê´€ë ¨ ì´ìŠˆ í˜„í™©

## 2. ğŸ¯ SKì—ë„ˆì§€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- ê¸ì •ì  ìš”ì¸
- ë¶€ì •ì  ìš”ì¸

## 3. ğŸ” ì£¼ìš” ê¸°íšŒìš”ì¸ê³¼ ìœ„í—˜ìš”ì¸
- ë‹¨ê¸° ê¸°íšŒ ìš”ì¸
- ì£¼ìš” ë¦¬ìŠ¤í¬ í¬ì¸íŠ¸

## 4. ğŸ¢ ê²½ìŸì‚¬ ëŒ€ë¹„ í¬ì§€ì…˜
- ì‹œì¥ ë‚´ ìƒëŒ€ì  ìœ„ì¹˜
- ê²½ìŸ ìš°ìœ„/ì—´ìœ„ ìš”ì†Œ

## 5. ğŸ”® í–¥í›„ 3-6ê°œì›” ì „ë§
- ì˜ˆìƒ ì‹œë‚˜ë¦¬ì˜¤
- ì£¼ìš” ë³€ìˆ˜ë“¤

## 6. ğŸ’¼ íˆ¬ìì/ê²½ì˜ì§„ì„ ìœ„í•œ ì „ëµ ì œì•ˆ
- ì‹¤í–‰ ê°€ëŠ¥í•œ ëŒ€ì‘ ë°©ì•ˆ
- ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  ì§€í‘œ

ì‹¤ë¬´ì§„ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            response = self.model.generate_content(prompt)
            return response.text
        
        except Exception as e:
            return f"AI ë‰´ìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ==========================
# ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤
# ==========================

def create_sk_bar_chart(chart_df):
    """SKì—ë„ˆì§€ ê°•ì¡° ë§‰ëŒ€ ì°¨íŠ¸"""
    if chart_df.empty or not PLOTLY_AVAILABLE:
        return None
    
    # íŒŒìŠ¤í…” ìƒ‰ìƒ ë§¤í•‘
    companies = chart_df['íšŒì‚¬'].unique() if 'íšŒì‚¬' in chart_df.columns else []
    color_discrete_map = {}
    for company in companies:
        color_discrete_map[company] = get_company_color(company, companies)
    
    fig = px.bar(
        chart_df,
        x='ì§€í‘œ' if 'ì§€í‘œ' in chart_df.columns else chart_df.columns[0],
        y='ìˆ˜ì¹˜' if 'ìˆ˜ì¹˜' in chart_df.columns else chart_df.columns[1],
        color='íšŒì‚¬' if 'íšŒì‚¬' in chart_df.columns else None,
        title="ğŸ’¼ SKì—ë„ˆì§€ vs ê²½ìŸì‚¬ ìˆ˜ìµì„± ì§€í‘œ ë¹„êµ",
        height=450,
        text='ìˆ˜ì¹˜' if 'ìˆ˜ì¹˜' in chart_df.columns else None,
        color_discrete_map=color_discrete_map,
        barmode='group'
    )
    
    if 'ìˆ˜ì¹˜' in chart_df.columns:
        fig.update_traces(
            texttemplate='%{text:.2f}%',
            textposition='outside',
            textfont=dict(size=12)
        )
    
    fig.update_layout(
        yaxis=dict(title="ìˆ˜ì¹˜", title_font_size=14, tickfont=dict(size=12)),
        xaxis=dict(title="ì¬ë¬´ ì§€í‘œ", tickangle=45, title_font_size=14, tickfont=dict(size=12)),
        legend=dict(font=dict(size=12)),
        title_font_size=16,
        font=dict(size=12)
    )
    
    return fig

def create_sk_radar_chart(chart_df):
    """SKì—ë„ˆì§€ ì¤‘ì‹¬ ë ˆì´ë” ì°¨íŠ¸"""
    if chart_df.empty or not PLOTLY_AVAILABLE:
        return None
    
    companies = chart_df['íšŒì‚¬'].unique() if 'íšŒì‚¬' in chart_df.columns else []
    metrics = chart_df['ì§€í‘œ'].unique() if 'ì§€í‘œ' in chart_df.columns else []
    
    fig = go.Figure()
    
    for i, company in enumerate(companies):
        company_data = chart_df[chart_df['íšŒì‚¬'] == company] if 'íšŒì‚¬' in chart_df.columns else chart_df
        values = company_data['ìˆ˜ì¹˜'].tolist() if 'ìˆ˜ì¹˜' in company_data.columns else []
        
        if values:
            values.append(values[0])  # ë‹«íŒ ë„í˜•ì„ ìœ„í•´ ì²« ë²ˆì§¸ ê°’ì„ ë§ˆì§€ë§‰ì— ì¶”ê°€
            theta_labels = list(metrics) + [metrics[0]] if len(metrics) > 0 else ['ì§€í‘œ1']
        else:
            continue
        
        # íŒŒìŠ¤í…” ìƒ‰ìƒ ì ìš©
        color = get_company_color(company, companies)
        
        # SKì—ë„ˆì§€ëŠ” íŠ¹ë³„í•œ ìŠ¤íƒ€ì¼
        if 'SK' in company:
            line_width = 5
            marker_size = 12
            name_style = f"**{company}**"  # êµµê²Œ í‘œì‹œ
        else:
            line_width = 3
            marker_size = 8
            name_style = company
        
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=theta_labels,
            fill='toself',
            name=name_style,
            line=dict(width=line_width, color=color),
            marker=dict(size=marker_size, color=color)
        ))
    
    max_value = chart_df['ìˆ˜ì¹˜'].max() if 'ìˆ˜ì¹˜' in chart_df.columns and not chart_df.empty else 10
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, max_value * 1.2],
                tickmode='linear',
                tick0=0,
                dtick=max_value * 0.2,
                tickfont=dict(size=14)
            ),
            angularaxis=dict(
                tickfont=dict(size=16)
            )
        ),
        title="ğŸ¯ SKì—ë„ˆì§€ vs ê²½ìŸì‚¬ ìˆ˜ìµì„± ì§€í‘œ ë¹„êµ",
        height=600,
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
            font=dict(size=14)
        ),
        title_font_size=20,
        font=dict(size=14)
    )
    
    return fig

def create_quarterly_trend_chart(quarterly_df):
    """ë¶„ê¸°ë³„ ì¶”ì´ ì°¨íŠ¸ ìƒì„±"""
    if quarterly_df.empty or not PLOTLY_AVAILABLE:
        return None
    
    fig = go.Figure()
    companies = quarterly_df['íšŒì‚¬'].unique()
    
    for company in companies:
        company_data = quarterly_df[quarterly_df['íšŒì‚¬'] == company]
        
        # íŒŒìŠ¤í…” ìƒ‰ìƒ ì ìš©
        line_color = get_company_color(company, companies)
        
        # SKì—ë„ˆì§€ëŠ” íŠ¹ë³„í•œ ìŠ¤íƒ€ì¼
        if 'SK' in company:
            line_width = 4
            marker_size = 10
            name_style = f"**{company}**"
        else:
            line_width = 2
            marker_size = 6
            name_style = company
        
        # ë§¤ì¶œì•¡ ì¶”ì´
        if 'ë§¤ì¶œì•¡' in company_data.columns:
            fig.add_trace(go.Scatter(
                x=company_data['ë¶„ê¸°'],
                y=company_data['ë§¤ì¶œì•¡'],
                mode='lines+markers',
                name=f"{name_style} ë§¤ì¶œì•¡",
                line=dict(color=line_color, width=line_width),
                marker=dict(size=marker_size, color=line_color),
                yaxis='y'
            ))
        
        # ì˜ì—…ì´ìµë¥  ì¶”ì´ (ë³´ì¡° ì¶•)
        if 'ì˜ì—…ì´ìµë¥ ' in company_data.columns:
            fig.add_trace(go.Scatter(
                x=company_data['ë¶„ê¸°'],
                y=company_data['ì˜ì—…ì´ìµë¥ '],
                mode='lines+markers',
                name=f"{name_style} ì˜ì—…ì´ìµë¥ ",
                line=dict(color=line_color, width=line_width, dash='dash'),
                marker=dict(size=marker_size, color=line_color, symbol='diamond'),
                yaxis='y2'
            ))
    
    fig.update_layout(
        title="ğŸ“ˆ ë¶„ê¸°ë³„ ì¬ë¬´ì„±ê³¼ ì¶”ì´ ë¶„ì„ (SKì—ë„ˆì§€ vs ê²½ìŸì‚¬)",
        xaxis=dict(
            title="ë¶„ê¸°",
            title_font_size=16,
            tickfont=dict(size=14)
        ),
        yaxis=dict(
            title="ë§¤ì¶œì•¡ (ì¡°ì›)",
            side="left",
            title_font_size=16,
            tickfont=dict(size=14)
        ),
        yaxis2=dict(
            title="ì˜ì—…ì´ìµë¥  (%)",
            side="right",
            overlaying="y",
            title_font_size=16,
            tickfont=dict(size=14)
        ),
        height=600,
        hovermode='x unified',
        legend=dict(
            font=dict(size=14)
        ),
        title_font_size=20,
        font=dict(size=14)
    )
    
    return fig
    
# ==========================
# DART ì¶œì²˜ í…Œì´ë¸” ìƒì„± í•¨ìˆ˜ (ë§í¬ ê°œì„ )
# ==========================

def create_dart_source_table(dart_collector, collected_companies, analysis_year):
    """DART ì¶œì²˜ ì •ë³´ í…Œì´ë¸” ìƒì„± (í´ë¦­ ê°€ëŠ¥í•œ ë§í¬)"""
    if not hasattr(dart_collector, 'source_tracking') or not dart_collector.source_tracking:
        return pd.DataFrame()
    
    source_data = []
    for company, info in dart_collector.source_tracking.items():
        if company in collected_companies:
            # ìœ íš¨í•œ DART ë§í¬ ìƒì„±
            rcept_no = info.get('rcept_no', 'N/A')
            if rcept_no and rcept_no != 'N/A':
                dart_url = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
            else:
                dart_url = "https://dart.fss.or.kr"
            
            source_data.append({
                'íšŒì‚¬ëª…': company,
                'ë³´ê³ ì„œ ìœ í˜•': info.get('report_type', 'ì¬ë¬´ì œí‘œ'),
                'ì—°ë„': info.get('year', analysis_year),
                'íšŒì‚¬ì½”ë“œ': info.get('company_code', 'N/A'),
                'DART ë°”ë¡œê°€ê¸°': dart_url,
                'ì ‘ìˆ˜ë²ˆí˜¸': rcept_no
            })
    
    return pd.DataFrame(source_data)

# ==========================
# PDF ìƒì„± í•¨ìˆ˜ (ìª½ë²ˆí˜¸ ì¶”ê°€ + ì˜¤ë¥˜ ìˆ˜ì •)
# ==========================
# ---------------------------------------------------------------------
#  PDF - ONE-SHOT REPLACEMENT
#  ë¶™ì—¬ ë„£ì„ ìœ„ì¹˜ : ê¸°ì¡´ create_enhanced_pdf_report ì •ì˜ ìë¦¬
# ---------------------------------------------------------------------
def create_enhanced_pdf_report(
        financial_data=None,
        news_data=None,
        insights:str|None=None,
        selected_charts:list|None=None
):
    """
    â€¢ ì œëª©  : ë§‘ì€ê³ ë”• Bold 20pt
    â€¢ ë³¸ë¬¸  : ì‹ ëª…ì¡° 12pt, ì¤„ê°„ê²© 170 %
    â€¢ AI ì¸ì‚¬ì´íŠ¸ : ë²ˆí˜¸ ë¶™ì€ ì œëª©ì€ êµµê²Œ, ë³¸ë¬¸ì€ í‰ë¬¸(ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±°)
    â€¢ í‘œ     : ReportLab Table ë¡œ ì¶œë ¥
    â€¢ ì°¨íŠ¸   : Plotly figure ë¦¬ìŠ¤íŠ¸(selected_charts) PNG ë¡œ ì‚½ì…
    """
    if not PDF_AVAILABLE:
        st.error("reportlab ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return None

    # ---------- 1. ë‚´ë¶€ í—¬í¼ ----------
    import re, tempfile
    def _clean_ai_text(raw:str)->list[tuple[str,str]]:
        """
        ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±° í›„
        ('title'|'body', line) í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        """
        raw = re.sub(r'[*_`#>~]', '', raw)      # êµµê²ŒÂ·ì´íƒ¤ë¦­Â·í‘œì‹œ ì œê±°
        blocks = []
        for ln in raw.splitlines():
            ln = ln.strip()
            if not ln:
                continue
            if re.match(r'^\d+(\.\d+)*\s', ln):    # 1.  / 1.1 ì²˜ëŸ¼ ì‹œì‘
                blocks.append(('title', ln))
            else:
                blocks.append(('body', ln))
        return blocks

    def _ascii_block_to_table(lines:list[str]):
        """
        íŒŒì´í”„(|) ë¡œ ë§Œë“  ASCII í‘œ â†’ ReportLab Table ë¡œ ë³€í™˜
        lines : '|' ê°€ í¬í•¨ëœ ì—°ì† í–‰ ë¦¬ìŠ¤íŠ¸
        ë°˜í™˜    : reportlab.platypus.Table ê°ì²´
        """
        header = [c.strip() for c in lines[0].split('|') if c.strip()]
        data   = []
        for ln in lines[2:]:         # êµ¬ë¶„ì„ (----) ì œì™¸
            cols = [c.strip() for c in ln.split('|') if c.strip()]
            if len(cols)==len(header):
                data.append(cols)
        if not data:
            return None
        tbl = Table([header]+data)
        tbl.setStyle(TableStyle([
            ('GRID',  (0,0), (-1,-1), 0.5, colors.black),
            ('BACKGROUND',(0,0),(-1,0), colors.HexColor('#E31E24')),
            ('TEXTCOLOR',(0,0),(-1,0), colors.white),
            ('ALIGN',(0,0),(-1,-1),'CENTER'),
            ('FONTNAME',(0,0),(-1,0),'KoreanBold'),
            ('FONTNAME',(0,1),(-1,-1),'Korean'),
            ('FONTSIZE',(0,0),(-1,-1),8),
            ('ROWBACKGROUNDS',(0,1),(-1,-1),
                [colors.whitesmoke, colors.HexColor('#F7F7F7')]),
        ]))
        return tbl
    # ---------- 2. í°íŠ¸ ë“±ë¡ ----------
# 3-1. ì‚¬ìš©í•  ê¸€ê¼´ ê²½ë¡œ(ìœˆë„Â·macÂ·ë¦¬ëˆ…ìŠ¤) â€• í•„ìš”í•œ ê²ƒë§Œ ë‚¨ê²¨ë„ ë¬´ë°©
# ---------- 2. í°íŠ¸ ë“±ë¡ ----------
    font_paths = {
        "Korean": [                                 # â† ì¶”ê°€
            "C:/Windows/Fonts/malgun.ttf",          # ë³¸ë¬¸ìš© ê°€ë³€-í­
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
        ],
        "KoreanBold": [
            "C:/Windows/Fonts/malgunbd.ttf",
            "/System/Library/Fonts/AppleSDGothicNeo.ttc"
        ],
        "KoreanSerif": [
            "C:/Windows/Fonts/batang.ttc",
            "/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf"
        ]
    }

    for name, paths in font_paths.items():
        for p in paths:
            if os.path.exists(p):
                try:
                    pdfmetrics.registerFont(TTFont(name, p))
                except Exception:
                    # ì´ë¯¸ ë“±ë¡ë¼ ìˆê±°ë‚˜ ë‹¤ë¥¸ ì´ìœ ë¡œ ì‹¤íŒ¨í•œ ê²½ìš° ë¬´ì‹œ
                    pass
                break  # ì²« ë²ˆì§¸ë¡œ ì„±ê³µ(ë˜ëŠ” ì‹œë„)í•œ ê²½ë¡œ ë’¤ì—ëŠ” ë°˜ë³µ ì¢…ë£Œ

    # ---------- 3. ìŠ¤íƒ€ì¼ ----------
    styles = getSampleStyleSheet()
    TITLE_STYLE = ParagraphStyle(
        'TITLE',
        fontName='KoreanBold' if 'KoreanBold' in pdfmetrics.getRegisteredFontNames() else 'Helvetica-Bold',
        fontSize=20,
        leading=34,
        spaceAfter=18
    )
    HEADING_STYLE = ParagraphStyle(
        'HEADING',
        fontName='KoreanBold' if 'KoreanBold' in pdfmetrics.getRegisteredFontNames() else 'Helvetica-Bold',
        fontSize=14,
        leading=23.8,
        textColor=colors.HexColor('#E31E24'),
        spaceBefore=16,
        spaceAfter=10
    )
    BODY_STYLE = ParagraphStyle(
        'BODY',
        fontName='KoreanSerif' if 'KoreanSerif' in pdfmetrics.getRegisteredFontNames() else 'Times-Roman',
        fontSize=12,
        leading=20.4,
        spaceAfter=6
    )

    # ---------- 4. PDF ì‘ì„± ----------
    buff = io.BytesIO()
    def _page_no(canvas, doc):
        canvas.setFont('Helvetica', 9)
        canvas.drawCentredString(letter[0]/2, 18, f"- {canvas.getPageNumber()} -")

    doc = SimpleDocTemplate(buff, pagesize=letter,
                            leftMargin=54, rightMargin=54,
                            topMargin=54, bottomMargin=54)

    story = []

    # 4-1 ì œëª© & ë©”íƒ€
    story.append(Paragraph("SKì—ë„ˆì§€ ê²½ìŸì‚¬ ë¶„ì„ ë³´ê³ ì„œ", TITLE_STYLE))
    story.append(Paragraph("ë³´ê³ ì¼ì: 2024ë…„ 10ì›” 26ì¼    "
                           "ë³´ê³ ëŒ€ìƒ: SKì—ë„ˆì§€ ì „ëµê¸°íšíŒ€    "
                           "ë³´ê³ ì: ì „ëµê¸°íšíŒ€", BODY_STYLE))
    story.append(Spacer(1, 12))

    # 4-2 ì¬ë¬´ í‘œ
    if financial_data is not None and not financial_data.empty:
        story.append(Paragraph("1. ì¬ë¬´ë¶„ì„ ê²°ê³¼", HEADING_STYLE))
        # '_ì›ì‹œê°’' ì œì™¸
        df_disp = financial_data[[c for c in financial_data.columns
                                  if not c.endswith('_ì›ì‹œê°’')]].copy()
        tbl = Table([df_disp.columns.tolist()] + df_disp.values.tolist(),
                    repeatRows=1)
        tbl.setStyle(TableStyle([
            ('GRID',(0,0),(-1,-1),0.5,colors.black),
            ('BACKGROUND',(0,0),(-1,0),colors.HexColor('#F2F2F2')),
            ('FONTNAME',(0,0),(-1,0),'KoreanBold'),
            ('FONTNAME',(0,1),(-1,-1),'KoreanSerif'),
            ('FONTSIZE',(0,0),(-1,-1),8),
            ('ALIGN',(0,0),(-1,-1),'CENTER')
        ]))
        story.append(tbl)
        story.append(Spacer(1, 18))

    # 4-3 ë‰´ìŠ¤ ìš”ì•½
    if news_data is not None and not news_data.empty:
        story.append(Paragraph("2. ìµœì‹  ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸", HEADING_STYLE))
        for i, title in enumerate(news_data["ì œëª©"].head(5), 1):
            story.append(Paragraph(f"{i}. {title}", BODY_STYLE))
        story.append(Spacer(1, 12))

    # 4-4 AI ì¸ì‚¬ì´íŠ¸
    if insights:
        story.append(PageBreak())
        story.append(Paragraph("3. AI ì¸ì‚¬ì´íŠ¸", HEADING_STYLE))
        blocks = _clean_ai_text(insights)
        ascii_buf = []
        for typ, ln in blocks:
            if '|' in ln:                 # ASCII í‘œ í›„ë³´
                ascii_buf.append(ln)
                continue
            # ë¨¼ì € ë²„í¼ flush
            if ascii_buf:
                tbl = _ascii_block_to_table(ascii_buf)
                if tbl: story.append(tbl)
                story.append(Spacer(1, 12))
                ascii_buf.clear()
            # ì •ìƒ í…ìŠ¤íŠ¸
            if typ=='title':
                story.append(Paragraph(f"<b>{ln}</b>", BODY_STYLE))
            else:
                story.append(Paragraph(ln, BODY_STYLE))
        # ëì— ë‚¨ì€ í‘œ flush
        if ascii_buf:
            tbl = _ascii_block_to_table(ascii_buf)
            if tbl: story.append(tbl)

    # 4-5 ì°¨íŠ¸
    if selected_charts and PLOTLY_AVAILABLE:
        story.append(PageBreak())
        story.append(Paragraph("4. ì‹œê°í™” ì°¨íŠ¸", HEADING_STYLE))
        for fig in selected_charts:
            try:
                img_bytes = fig.to_image(format="png", width=700, height=400)
                with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:
                    tmp.write(img_bytes); tmp_path = tmp.name
                story.append(RLImage(tmp_path, width=500, height=280))
                story.append(Spacer(1, 16))
                os.unlink(tmp_path)
            except Exception as e:
                story.append(Paragraph(f"ì°¨íŠ¸ ì‚½ì… ì˜¤ë¥˜: {e}", BODY_STYLE))

    # 4-6 ë¹Œë“œ
    doc.build(story, onFirstPage=_page_no, onLaterPages=_page_no)
    buff.seek(0)
    return buff.getvalue()

    if not PDF_AVAILABLE:
        st.error("PDF ìƒì„±ì„ ìœ„í•´ reportlab ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return None

    try:
        pdf_buffer = io.BytesIO()
        
        # ìª½ë²ˆí˜¸ê°€ ìˆëŠ” í˜ì´ì§€ í…œí”Œë¦¿ ìƒì„±
        def add_page_number(canvas, doc):
            """ìª½ë²ˆí˜¸ ì¶”ê°€ í•¨ìˆ˜"""
            canvas.saveState()
            canvas.setFont('Helvetica', 10)
            page_num = canvas.getPageNumber()
            text = f"- {page_num} -"
            canvas.drawString(letter[0]/2 - 10, 30, text)
            canvas.restoreState()

        doc = SimpleDocTemplate(
            pdf_buffer, 
            pagesize=letter,
            topMargin=72,
            bottomMargin=72
        )

        # í•œê¸€ í°íŠ¸ ë“±ë¡
        korean_font_registered = False
        korean_font_paths = [
            'C:/Windows/Fonts/malgun.ttf',
            'C:/Windows/Fonts/gulim.ttc',
            'C:/Windows/Fonts/NanumGothic.ttf',
            '/System/Library/Fonts/AppleGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        ]
        
        for font_path in korean_font_paths:
            if os.path.exists(font_path):
                try:
                    pdfmetrics.registerFont(TTFont('KoreanSerif', font_path))
                    korean_font_registered = True
                    break
                except:
                    continue

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        styles = getSampleStyleSheet()
        
        # í•œê¸€ ì§€ì› ìŠ¤íƒ€ì¼
        title_style = ParagraphStyle(
            'KoreanTitle',
            parent=styles['Title'],
            fontName='KoreanBold' if korean_font_registered else 'Helvetica-Bold',
            fontSize=20,
            textColor=colors.Color(227/255, 30/255, 36/255),
            spaceAfter=30,
            encoding='utf-8'
        )
        
        heading_style = ParagraphStyle(
            'KoreanHeading',
            parent=styles['Heading1'],
            fontName='KoreanBold' if korean_font_registered else 'Helvetica-Bold',
            fontSize=16,
            textColor=colors.Color(227/255, 30/255, 36/255),
            spaceBefore=20,
            spaceAfter=15,
            encoding='utf-8'
        )
        
        normal_style = ParagraphStyle(
            'KoreanNormal',
            parent=styles['Normal'],
            fontName='KoreanSerif' if korean_font_registered else 'Helvetica',
            fontSize=11,
            spaceAfter=12,
            encoding='utf-8'
        )

        story = []

        # ì œëª©
        story.append(Paragraph("âš¡ SKì—ë„ˆì§€ ê²½ìŸì‚¬ ë¶„ì„ ë³´ê³ ì„œ", title_style))
        story.append(Spacer(1, 20))

        # ìƒì„± ì •ë³´
        story.append(Paragraph(f"ğŸ“… ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}", normal_style))
        story.append(Paragraph("ğŸ¯ ë°ì´í„° ì¶œì²˜: DART API (ì‹¤ì œ ì¬ë¬´ë°ì´í„°)", normal_style))
        story.append(Paragraph("ğŸ¤– AI ë¶„ì„: Google Gemini 1.5", normal_style))
        story.append(Spacer(1, 30))

        section_number = 1

        # ì¬ë¬´ë¶„ì„ ì„¹ì…˜
        if financial_data is not None and not financial_data.empty:
            story.append(Paragraph(f"{section_number}. ğŸ“Š ì¬ë¬´ë¶„ì„ ê²°ê³¼", heading_style))
            story.append(Spacer(1, 15))

            # í…Œì´ë¸” ìƒì„± (í•œê¸€ ì§€ì›)
            table_data = []
            headers = [str(col)[:20] for col in financial_data.columns if not col.endswith('_ì›ì‹œê°’')]
            table_data.append(headers)

            # ë°ì´í„° í–‰ ì¶”ê°€
            for _, row in financial_data.head(15).iterrows():
                row_data = []
                for col in financial_data.columns:
                    if not col.endswith('_ì›ì‹œê°’'):
                        cell_value = row[col]
                        if pd.isna(cell_value):
                            cell_str = '-'
                        else:
                            cell_str = str(cell_value)[:20]
                        row_data.append(cell_str)
                table_data.append(row_data)

            # í…Œì´ë¸” ìŠ¤íƒ€ì¼ë§
            table = Table(table_data)
            table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.Color(227/255, 30/255, 36/255)),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'KoreanSerif' if korean_font_registered else 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 9),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('FONTSIZE', (0, 1), (-1, -1), 8),
                ('FONTNAME', (0, 1), (-1, -1), 'KoreanSerif' if korean_font_registered else 'Helvetica'),
                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.Color(0.95, 0.95, 0.95)]),
            ]))

            story.append(table)
            story.append(Spacer(1, 25))
            section_number += 1

        # ë‰´ìŠ¤ë¶„ì„ ì„¹ì…˜
        if news_data is not None and not news_data.empty:
            story.append(Paragraph(f"{section_number}. ğŸ“° ë‰´ìŠ¤ë¶„ì„ ê²°ê³¼", heading_style))
            story.append(Spacer(1, 10))
            story.append(Paragraph(f"ì´ {len(news_data)}ê±´ì˜ ë‰´ìŠ¤ ë¶„ì„", normal_style))
            story.append(Spacer(1, 10))

            # ìƒìœ„ 5ê°œ ë‰´ìŠ¤ë§Œ í‘œì‹œ
            for idx, (_, row) in enumerate(news_data.head(5).iterrows()):
                title = str(row.get('ì œëª©', 'N/A'))[:50] + "..."
                story.append(Paragraph(f"{idx+1}. {title}", normal_style))
                story.append(Spacer(1, 5))
            
            section_number += 1

        # AI ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜
        if insights:
            story.append(PageBreak())
            story.append(Paragraph(f"{section_number}. ğŸ¤– AI ì¸ì‚¬ì´íŠ¸", heading_style))
            story.append(Spacer(1, 15))

            # ì¸ì‚¬ì´íŠ¸ ì²˜ë¦¬
            insight_text = str(insights)
            lines = insight_text.split('\n')
            
            for line in lines:
                if line.strip():
                    # ì œëª© ì²˜ë¦¬
                    if line.startswith('##'):
                        title_text = line.replace('##', '').strip()
                        story.append(Paragraph(title_text, heading_style))
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸
                        clean_line = line.strip()
                        if clean_line:
                            story.append(Paragraph(clean_line, normal_style))
                    story.append(Spacer(1, 8))

        # ì°¨íŠ¸ ì„¹ì…˜ (ì„ íƒì‚¬í•­)
        if selected_charts and PLOTLY_AVAILABLE:
            story.append(Paragraph(f"{section_number}. ğŸ“Š ì°¨íŠ¸ ë¶„ì„", heading_style))
            story.append(Spacer(1, 15))
            
            # Plotly ì°¨íŠ¸ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì‚½ì…
            for idx, fig in enumerate(selected_charts):
                try:
                    import tempfile
                    img_bytes = fig.to_image(format="png", width=800, height=500)
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:
                        tmp.write(img_bytes)
                        tmp_path = tmp.name
                    
                    story.append(RLImage(tmp_path, width=500, height=300))
                    story.append(Spacer(1, 20))
                    
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        os.unlink(tmp_path)
                    except:
                        pass
                        
                except Exception as e:
                    story.append(Paragraph(f"ì°¨íŠ¸ {idx+1} ì‚½ì… ì˜¤ë¥˜: {str(e)}", normal_style))
                    story.append(Spacer(1, 10))

        # í‘¸í„°
        story.append(Spacer(1, 50))
        story.append(Paragraph("ğŸ”— ë³¸ ë³´ê³ ì„œëŠ” SKì—ë„ˆì§€ ê²½ìŸì‚¬ ë¶„ì„ ëŒ€ì‹œë³´ë“œì—ì„œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.", normal_style))
        story.append(Paragraph("ğŸ“Š ì‹¤ì œ DART API ë°ì´í„° + Google Gemini AI ë¶„ì„ ê¸°ë°˜", normal_style))

        # PDF ë¹Œë“œ (ìª½ë²ˆí˜¸ í¬í•¨)
        doc.build(story, onFirstPage=add_page_number, onLaterPages=add_page_number)
        pdf_buffer.seek(0)
        return pdf_buffer.getvalue()

    except Exception as e:
        st.error(f"PDF ìƒì„± ì˜¤ë¥˜: {e}")
        return None
        
def create_excel_report(financial_data=None, news_data=None, insights=None):
    """Excel ë³´ê³ ì„œ ìƒì„±"""
    try:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # ì¬ë¬´ë¶„ì„ ì‹œíŠ¸
            if financial_data is not None and not financial_data.empty:
                # '_ì›ì‹œê°’' ì»¬ëŸ¼ ì œê±°
                clean_financial = financial_data[[col for col in financial_data.columns if not col.endswith('_ì›ì‹œê°’')]]
                clean_financial.to_excel(writer, sheet_name='ì¬ë¬´ë¶„ì„', index=False)
            
            # ë‰´ìŠ¤ë¶„ì„ ì‹œíŠ¸
            if news_data is not None and not news_data.empty:
                news_data.to_excel(writer, sheet_name='ë‰´ìŠ¤ë¶„ì„', index=False)
            
            # ì¸ì‚¬ì´íŠ¸ ì‹œíŠ¸
            if insights:
                insight_df = pd.DataFrame({
                    'êµ¬ë¶„': ['AI ì¸ì‚¬ì´íŠ¸'],
                    'ë‚´ìš©': [str(insights)]
                })
                insight_df.to_excel(writer, sheet_name='AIì¸ì‚¬ì´íŠ¸', index=False)
        
        output.seek(0)
        return output.getvalue()
    
    except Exception as e:
        st.error(f"Excel ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# ==========================
# ë©”ì¸ í•¨ìˆ˜
# ==========================
def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    st.title("âš¡ SKì—ë„ˆì§€ ê²½ìŸì‚¬ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("**DART API + RSS ë‰´ìŠ¤ + êµ¬ê¸€ì‹œíŠ¸ + Gemini AI ì¸ì‚¬ì´íŠ¸ í†µí•©**")
    
    # ìš”êµ¬ì‚¬í•­ ë§ì¶¤ íƒ­ êµ¬ì„±
    tabs = st.tabs(["ğŸ“ˆ ì¬ë¬´ë¶„ì„ (DART ìë™)", "ğŸ“ ìˆ˜ë™ XBRL ì—…ë¡œë“œ", "ğŸ“° ë‰´ìŠ¤ë¶„ì„", "ğŸ“„ ë³´ê³ ì„œ ìƒì„±"])
    
    # ==========================
    # íƒ­1: ì¬ë¬´ë¶„ì„ (DART ìë™í™”) + AI ì¸ì‚¬ì´íŠ¸ + ìƒˆë¡œê³ ì¹¨
    # ==========================
    
    with tabs[0]:
        st.subheader("ğŸ“ˆ ì¬ë¬´ë¶„ì„ (DART ìë™í™”)")
        st.write("**ê¸°ì—…ì„ ì„ íƒí•˜ê³  ë¶„ì„ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ DARTì—ì„œ ê°€ì ¸ì˜¨ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì‹œê°í™”/ì°¨íŠ¸ë¥¼ ê·¸ë ¤ì¤ë‹ˆë‹¤.**")
        
        # ê¸°ì—… ì„ íƒ
        selected_companies = st.multiselect(
            "ë¶„ì„í•  ê¸°ì—… ì„ íƒ",
            ["SKì—ë„ˆì§€", "GSì¹¼í…ìŠ¤", "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "S-Oil"],
            default=["SKì—ë„ˆì§€", "GSì¹¼í…ìŠ¤"],
            key="companies_selection"
        )
        
        analysis_year = st.selectbox("ë¶„ì„ ì—°ë„", ["2024", "2023", "2022"], index=0)
        
        # ë¶„ì„ ë²„íŠ¼
        if st.button("ğŸš€ DART ìë™ë¶„ì„ ì‹œì‘", type="primary"):
            if not selected_companies:
                st.error("ë¶„ì„í•  ê¸°ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("DART APIì—ì„œ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
                    # DART API ìˆ˜ì§‘ (í”„ë¡œê·¸ë ˆìŠ¤ë°” í¬í•¨)
                    dart_collector = DartAPICollector(DART_API_KEY)
                    sk_processor = SKFinancialDataProcessor()
                    
                    dataframes = collect_financial_data_with_progress(
                        dart_collector, sk_processor, selected_companies, analysis_year
                    )
                    
                    if dataframes:
                        # ë°ì´í„° ë³‘í•©
                        merged_df = sk_processor.merge_company_data(dataframes)
                        st.session_state.financial_data = merged_df
                        st.session_state.selected_companies = selected_companies
                        
                        # Gemini AI ì¬ë¬´ ì¸ì‚¬ì´íŠ¸ ìƒì„±
                        gemini_generator = GeminiInsightGenerator()
                        with st.spinner("ğŸ¤– AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘..."):
                            financial_insight = gemini_generator.generate_financial_insight(merged_df)
                            st.session_state.financial_insight = financial_insight
                        
                        st.success(f"âœ… {len(selected_companies)}ê°œ íšŒì‚¬ DART ë¶„ì„ ì™„ë£Œ!")
                    else:
                        st.error("ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ì¬ë¬´ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if st.session_state.financial_data is not None and not st.session_state.financial_data.empty:
            st.markdown("---")
            
            # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ ì¶”ê°€
            col1, col2 = st.columns([3, 1])
            with col1:
                st.subheader("ğŸ’° ì¬ë¬´ë¶„ì„ ê²°ê³¼")
            with col2:
                if st.button("ğŸ”„ AI ì¸ì‚¬ì´íŠ¸ ìƒˆë¡œê³ ì¹¨", key="refresh_financial_insight"):
                    gemini_generator = GeminiInsightGenerator()
                    with st.spinner("ğŸ¤– AI ì¸ì‚¬ì´íŠ¸ ì¬ìƒì„± ì¤‘..."):
                        financial_insight = gemini_generator.generate_financial_insight(st.session_state.financial_data)
                        st.session_state.financial_insight = financial_insight
                        st.rerun()
            
            # ì¬ë¬´ì œí‘œ í‘œì‹œ (_ì›ì‹œê°’ ì»¬ëŸ¼ ì™„ì „ ì œê±°)
            display_df = st.session_state.financial_data.copy()
            display_cols = [col for col in display_df.columns if not col.endswith('_ì›ì‹œê°’')]
            display_df = display_df[display_cols]
            
            st.dataframe(display_df, use_container_width=True)
            
            # DART ì¶œì²˜ ì •ë³´ í‘œì‹œ (ë§í¬ ê°œì„ )
            if st.session_state.selected_companies:
                dart_collector = DartAPICollector(DART_API_KEY)
                source_df = create_dart_source_table(dart_collector, st.session_state.selected_companies, analysis_year)
                if not source_df.empty:
                    st.subheader("ğŸ“Š DART ì „ìê³µì‹œì‹œìŠ¤í…œ ì¶œì²˜")
                    st.dataframe(
                        source_df,
                        use_container_width=True,
                        column_config={
                            "DART ë°”ë¡œê°€ê¸°": st.column_config.LinkColumn(
                                "ğŸ”— DART ë°”ë¡œê°€ê¸°",
                                help="í´ë¦­í•˜ë©´ í•´ë‹¹ ë³´ê³ ì„œë¡œ ì´ë™í•©ë‹ˆë‹¤"
                            )
                        }
                    )
                    st.caption("ğŸ’¡ ê¸ˆìœµê°ë…ì› ì „ìê³µì‹œì‹œìŠ¤í…œ(https://dart.fss.or.kr)ì—ì„œ ì œê³µí•˜ëŠ” ê³µì‹ ì¬ë¬´ì œí‘œ ë°ì´í„°ì…ë‹ˆë‹¤.")
            
            # ì‹œê°í™”/ì°¨íŠ¸
            st.subheader("ğŸ“Š ì‹œê°í™”/ì°¨íŠ¸")
            
            # ë¹„ìœ¨ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ì°¨íŠ¸ ìƒì„±
            ratio_data = display_df[display_df['êµ¬ë¶„'].str.contains('%', na=False)]
            
            if not ratio_data.empty and PLOTLY_AVAILABLE:
                # ì°¨íŠ¸ìš© ë°ì´í„° ì¤€ë¹„
                chart_data = []
                companies = [col for col in ratio_data.columns if col != 'êµ¬ë¶„']
                
                for _, row in ratio_data.iterrows():
                    for company in companies:
                        value_str = str(row[company]).replace('%', '')
                        try:
                            value = float(value_str)
                            chart_data.append({
                                'ì§€í‘œ': row['êµ¬ë¶„'],
                                'íšŒì‚¬': company,
                                'ìˆ˜ì¹˜': value
                            })
                        except:
                            continue
                
                if chart_data:
                    chart_df = pd.DataFrame(chart_data)
                    
                    # SKì—ë„ˆì§€ ê°•ì¡° ë§‰ëŒ€ì°¨íŠ¸
                    fig1 = create_sk_bar_chart(chart_df)
                    if fig1:
                        st.plotly_chart(fig1, use_container_width=True)
                    
                    # SKì—ë„ˆì§€ ì¤‘ì‹¬ ë ˆì´ë”ì°¨íŠ¸
                    fig2 = create_sk_radar_chart(chart_df)
                    if fig2:
                        st.plotly_chart(fig2, use_container_width=True)
            
            # ë¶„ê¸°ë³„ ì°¨íŠ¸ (í”„ë¡œê·¸ë ˆìŠ¤ë°” ê°œì„ )
            st.subheader("ğŸ“ˆ ë¶„ê¸°ë³„ ì°¨íŠ¸")
            
            if st.session_state.selected_companies:
                quarterly_collector = QuarterlyDataCollector(DartAPICollector(DART_API_KEY))
                quarterly_data_list = []
                
                for company in st.session_state.selected_companies:
                    quarterly_df = quarterly_collector.collect_quarterly_data(company, int(analysis_year))
                    if not quarterly_df.empty:
                        quarterly_data_list.append(quarterly_df)
                
                if quarterly_data_list:
                    # ë¶„ê¸°ë³„ ë°ì´í„° í†µí•©
                    quarterly_merged = pd.concat(quarterly_data_list, ignore_index=True)
                    st.session_state.quarterly_data = quarterly_merged
                    
                    fig_trend = create_quarterly_trend_chart(quarterly_merged)
                    if fig_trend:
                        st.plotly_chart(fig_trend, use_container_width=True)
            
            # Gemini AI ì¬ë¬´ ì¸ì‚¬ì´íŠ¸
            if st.session_state.financial_insight:
                st.subheader("ğŸ¤– AI ì¬ë¬´ ì¸ì‚¬ì´íŠ¸")
                st.markdown(st.session_state.financial_insight)
    
# ==========================
    # íƒ­2: ìˆ˜ë™ XBRL ì—…ë¡œë“œ
    # ==========================
    
# ==========================
# íƒ­2: ìˆ˜ë™ XBRL ì—…ë¡œë“œ (ì˜¤ë¥˜ ìˆ˜ì •)
# ==========================

    with tabs[1]:
        st.subheader("ğŸ“ ìˆ˜ë™ XBRL/XML íŒŒì¼ ì—…ë¡œë“œ")
        st.write("**XBRL/XML íŒŒì¼ì„ ì§ì ‘ ì—…ë¡œë“œí•˜ì—¬ ì¬ë¬´ì œí‘œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.**")
        
        processor = FinancialDataProcessor()
        
        # ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ
        uploaded_files = st.file_uploader(
            "XBRL/XML íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
            type=['xbrl', 'xml'],
            accept_multiple_files=True,
            key="manual_upload"
        )
        
        if uploaded_files:
            st.subheader("ğŸ“Š ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬")
            dataframes = []
            
            for uploaded_file in uploaded_files:
                st.write(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {uploaded_file.name}")
                df = processor.load_file(uploaded_file)
                
                if df is not None:
                    dataframes.append(df)
                    st.success(f"âœ… {uploaded_file.name} ì²˜ë¦¬ ì™„ë£Œ")
                    
                    # ê°œë³„ íšŒì‚¬ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    with st.expander(f"ğŸ“‹ {uploaded_file.name} ìƒì„¸ ë°ì´í„°"):
                        st.dataframe(df, use_container_width=True)
                else:
                    st.error(f"âŒ {uploaded_file.name} ì²˜ë¦¬ ì‹¤íŒ¨")
            
            if dataframes:
                # ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„
                st.subheader("ğŸ¢ ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„")
                
                # merged_df ì´ˆê¸°í™” (ì˜¤ë¥˜ ìˆ˜ì •)
                merged_df = None
                
                if len(dataframes) == 1:
                    st.write("**ğŸ“‹ ë‹¨ì¼ íšŒì‚¬ ì†ìµê³„ì‚°ì„œ**")
                    st.dataframe(dataframes[0], use_container_width=True)
                    st.session_state.manual_financial_data = dataframes[0]  # ë‹¨ì¼ íšŒì‚¬ë„ merged_dfë¡œ ì„¤ì •
                else:
                    # ë‹¤ì¤‘ íšŒì‚¬ ë¹„êµ
                    merged_df = processor.merge_company_data(dataframes)
                    st.write("**ğŸ“Š ê²½ìŸì‚¬ ë¹„êµ ì†ìµê³„ì‚°ì„œ**")
                    st.dataframe(merged_df, use_container_width=True)
                    st.session_state.manual_financial_data = merged_df
                
                # AI ë¶„ì„ ë¦¬í¬íŠ¸ (merged_dfê°€ ì •ì˜ëœ í›„ì— ì‹¤í–‰)
                if merged_df is not None and not merged_df.empty:
                    st.subheader("ğŸ’¡ AI ë¶„ì„ ë¦¬í¬íŠ¸")
                    report = processor.create_comparison_report(merged_df)
                    st.text(report)
                else:
                    st.error("âŒ ë¹„êµ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ==========================
    # íƒ­3: ë‰´ìŠ¤ë¶„ì„ (êµ¬ê¸€ì‹œíŠ¸ + RSS í†µí•© + ìƒˆë¡œê³ ì¹¨)
    # ==========================
    
    with tabs[2]:
        st.subheader("ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë¶„ì„")
        st.write("**êµ¬ê¸€ì‹œíŠ¸ ìë™í™” ë‰´ìŠ¤ + êµ­ë‚´ ì£¼ìš” ê²½ì œÂ·ì‚°ì—… RSSë¥¼ ìˆ˜ì§‘í•´ SKì—ë„ˆì§€ì™€ ê²½ìŸì‚¬ ë™í–¥ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.**")
        
        # ë‰´ìŠ¤ ìˆ˜ì§‘ ë²„íŠ¼
        if st.button("ğŸ”„ í†µí•© ë‰´ìŠ¤ ìˆ˜ì§‘/ê°±ì‹ ", type="primary", key="collect_news"):
            news_collector = SKNewsCollector()
            news_df = news_collector.collect_news()

            
            if not news_df.empty:
                st.session_state.news_data = news_df
                
                # Gemini AI ë‰´ìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
                gemini_generator = GeminiInsightGenerator()
                with st.spinner("ğŸ¤– ë‰´ìŠ¤ AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘..."):
                    keywords_set = set()
                    for kw_list in news_df["í‚¤ì›Œë“œ"].dropna():
                        keywords_set.update([kw.strip() for kw in str(kw_list).split(",")])
                    
                    news_insight = gemini_generator.generate_news_insight(
                        list(keywords_set),
                        news_df["ì œëª©"].tolist()
                    )
                    st.session_state.news_insight = news_insight
                
                st.success(f"âœ… ì´ {len(news_df)}ê°œ ë‰´ìŠ¤ í†µí•© ìˆ˜ì§‘ ì™„ë£Œ!")
            else:
                st.warning("ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë°ì´í„° í‘œì‹œ
        if st.session_state.news_data is not None:
            # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ ì¶”ê°€
            col1, col2 = st.columns([3, 1])
            with col1:
                st.subheader("ğŸ“‹ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡")
            with col2:
                if st.button("ğŸ”„ AI ì¸ì‚¬ì´íŠ¸ ìƒˆë¡œê³ ì¹¨", key="refresh_news_insight"):
                    gemini_generator = GeminiInsightGenerator()
                    with st.spinner("ğŸ¤– ë‰´ìŠ¤ AI ì¸ì‚¬ì´íŠ¸ ì¬ìƒì„± ì¤‘..."):
                        keywords_set = set()
                        for kw_list in st.session_state.news_data["í‚¤ì›Œë“œ"].dropna():
                            keywords_set.update([kw.strip() for kw in str(kw_list).split(",")])
                        
                        news_insight = gemini_generator.generate_news_insight(
                            list(keywords_set),
                            st.session_state.news_data["ì œëª©"].tolist()
                        )
                        st.session_state.news_insight = news_insight
                        st.rerun()
            
            st.dataframe(st.session_state.news_data, use_container_width=True)
            
            # ì¹´í…Œê³ ë¦¬ ë¶„í¬ ì°¨íŠ¸
            #if PLOTLY_AVAILABLE:
                #news_collector = SKNewsCollector()
                #fig_news = news_collector.create_keyword_analysis(st.session_state.news_data)
                #if fig_news:
                  #  st.plotly_chart(fig_news, use_container_width=True)
            
            # Gemini AI ë‰´ìŠ¤ ì¸ì‚¬ì´íŠ¸
            if st.session_state.news_insight:
                st.subheader("ğŸ¤– AI ë‰´ìŠ¤ ì¸ì‚¬ì´íŠ¸")
                st.markdown(st.session_state.news_insight)

# ==========================
# íƒ­4: ë³´ê³ ì„œ ìƒì„± ë° ì´ë©”ì¼ ë°œì†¡ (ê°œì„ ëœ UI + PDF ìª½ë²ˆí˜¸)
# ==========================

    with tabs[3]:
        st.subheader("ğŸ“„ í†µí•© ë³´ê³ ì„œ ìƒì„± & ì´ë©”ì¼ ì„œë¹„ìŠ¤ ë°”ë¡œê°€ê¸°")

        # 2ì—´ ë ˆì´ì•„ì›ƒ: PDF ìƒì„± + ì´ë©”ì¼ ì…ë ¥
        col1, col2 = st.columns([1, 1])

        with col1:
            st.write("**ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ**")
            # ë³´ê³ ì„œ í˜•ì‹ ì„ íƒ
            report_format = st.radio("íŒŒì¼ í˜•ì‹ ì„ íƒ", ["PDF", "Excel"], horizontal=True)
            
            if st.button("ğŸ“¥ ë³´ê³ ì„œ ìƒì„±", type="primary", key="make_report"):
                # ë°ì´í„° ìš°ì„ ìˆœìœ„: DART ìë™ > ìˆ˜ë™ ì—…ë¡œë“œ
                financial_data_for_report = None
                if st.session_state.financial_data is not None and not st.session_state.financial_data.empty:
                    financial_data_for_report = st.session_state.financial_data
                elif st.session_state.manual_financial_data is not None and not st.session_state.manual_financial_data.empty:
                    financial_data_for_report = st.session_state.manual_financial_data
                
                with st.spinner("ğŸ“„ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                    if report_format == "PDF":
                        file_bytes = create_enhanced_pdf_report(
                            financial_data=financial_data_for_report,
                            news_data=st.session_state.news_data,
                            insights=st.session_state.financial_insight or st.session_state.news_insight
                        )
                        filename = "SK_Energy_Analysis_Report.pdf"
                        mime_type = "application/pdf"
                    else:
                        file_bytes = create_excel_report(
                            financial_data=financial_data_for_report,
                            news_data=st.session_state.news_data,
                            insights=st.session_state.financial_insight or st.session_state.news_insight
                        )
                        filename = "SK_Energy_Analysis_Report.xlsx"
                        mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    
                    if file_bytes:
                        # ì„¸ì…˜ì— íŒŒì¼ ì •ë³´ ì €ì¥
                        st.session_state.generated_file = file_bytes
                        st.session_state.generated_filename = filename
                        st.session_state.generated_mime = mime_type
                        
                        st.download_button(
                            label="â¬‡ï¸ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                            data=file_bytes,
                            file_name=filename,
                            mime=mime_type
                        )
                        st.success("âœ… ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.error("âŒ ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
        with col2:
            st.write("**ğŸ“§ ì´ë©”ì¼ ì„œë¹„ìŠ¤ ë°”ë¡œê°€ê¸°**")

            mail_providers = {
                "ë„¤ì´ë²„": "https://mail.naver.com/",
                "êµ¬ê¸€(Gmail)": "https://mail.google.com/",
                "ë‹¤ìŒ": "https://mail.daum.net/",
                "ë„¤ì´íŠ¸": "https://mail.nate.com/",
                "ì•¼í›„": "https://mail.yahoo.com/",
                "ì•„ì›ƒë£©(Outlook)": "https://outlook.live.com/",
                "í”„ë¡œí†¤ë©”ì¼(ProtonMail)": "https://mail.proton.me/",
                "ì¡°í˜¸ë©”ì¼(Zoho Mail)": "https://mail.zoho.com/",
                "GMX ë©”ì¼": "https://www.gmx.com/",
                "ì•„ì´í´ë¼ìš°ë“œ(iCloud Mail)": "https://www.icloud.com/mail",
                "ë©”ì¼ë‹·ì»´(Mail.com)": "https://www.mail.com/",
                "AOL ë©”ì¼": "https://mail.aol.com/"
            }

            selected_provider = st.selectbox(
                "ë©”ì¼ ì„œë¹„ìŠ¤ ì„ íƒ",
                list(mail_providers.keys()),
                key="mail_provider_select"
            )
            url = mail_providers[selected_provider]

            st.markdown(
                f"[{selected_provider} ë©”ì¼ ë°”ë¡œê°€ê¸°]({url})",
                unsafe_allow_html=True
            )
            st.info("ì„ íƒí•œ ë©”ì¼ ì„œë¹„ìŠ¤ ë§í¬ê°€ ìƒˆ íƒ­ì—ì„œ ì—´ë¦½ë‹ˆë‹¤.")

            if st.session_state.get('generated_file'):
                st.download_button(
                    label=f"ğŸ“¥ {st.session_state.generated_filename} ë‹¤ìš´ë¡œë“œ",
                    data=st.session_state.generated_file,
                    file_name=st.session_state.generated_filename,
                    mime=st.session_state.generated_mime,
                    key="download_generated_report_btn"
                )
            else:
                st.info("ë¨¼ì € ë³´ê³ ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()
